{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install lightgbm\n",
    "%pip install torch\n",
    "%pip install group_lasso\n",
    "%pip install ISLP\n",
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.linear_model import (LinearRegression, \n",
    "                                  HuberRegressor,\n",
    "                                  ElasticNet)\n",
    "from sklearn.metrics import (mean_squared_error, \n",
    "                             r2_score)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import (TimeSeriesSplit, \n",
    "                                     ParameterGrid)\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.ensemble import (GradientBoostingRegressor,\n",
    "                              RandomForestRegressor as RF)\n",
    "from group_lasso import GroupLasso\n",
    "from datetime import datetime\n",
    "from joblib import Parallel, delayed\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and formatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read datafiles into dataframes.\n",
    "# y = the excess returns. X has the predictors.\n",
    "y = pd.read_csv('Dependent_y.csv', header=0, index_col=0)\n",
    "X = pd.read_csv('Features_X.csv', header=0, index_col=0)\n",
    "\n",
    "\n",
    "y.fillna(0, inplace=True) # Do we need this? Isn't it already done in Pre-Processing?\n",
    "\n",
    "# Converting data to Dates as index\n",
    "y.index = pd.to_datetime(y.index, format=\"%Y-%m\").to_period('M')\n",
    "X.index = pd.to_datetime(X.index, format=\"%Y-%m\").to_period('M')\n",
    "\n",
    "# Creating the weights of the stocks compared to the portfolio\n",
    "weights = pd.read_csv('Stocks_weights.csv', header=0)\n",
    "weights.index = weights['Date']\n",
    "weights = weights.drop('Date', axis=1)\n",
    "weights.index = pd.to_datetime(weights.index, format=\"%Y-%m\").to_period('M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def R_oos(num, den):\n",
    "    \"\"\"\n",
    "Calculates the Out Of Sample R-squared\n",
    "Input: \n",
    "    - num: Numerator\n",
    "    - den: Denomenator\n",
    "\n",
    "    Output: Out of sample R-squared\n",
    "    \"\"\"\n",
    "    R_oos_val = 1 - (np.sum(num)/np.sum(den))\n",
    "    return R_oos_val\n",
    "\n",
    "\n",
    "\n",
    "def val_fun(model, params: dict, X_trn, y_trn, X_vld, y_vld, max_iter=10, tol=1e-4):\n",
    "    \"\"\"\n",
    "Validates a model to get the best parameters\n",
    "Input: \n",
    "    - model: The model we are validating.\n",
    "    - params: A dictionary of parameters.\n",
    "    - X_trn: Predictors training set.\n",
    "    - y_trn: Dependent variable training set.\n",
    "    - X_vld: Predictors validation set.\n",
    "    - y_vld:Dependent variable validation set.\n",
    "    - max_iter: ...\n",
    "    - tol: ...\n",
    "\n",
    "    Output: Best parameters.\n",
    "    \"\"\"\n",
    "    best_ros = None\n",
    "    lst_params = list(ParameterGrid(params))\n",
    "    no_improvement_count = 0\n",
    "    for param in lst_params:\n",
    "        if best_ros == None:\n",
    "            mod = model().set_params(**param).fit(X_trn, y_trn)\n",
    "            y_pred = mod.predict(X_vld)\n",
    "            best_ros = R_oos(y_vld, y_pred)\n",
    "            best_param = param\n",
    "        else:\n",
    "            mod = model().set_params(**param).fit(X_trn, y_trn)\n",
    "            y_pred = mod.predict(X_vld)\n",
    "            ros = R_oos(y_vld, y_pred)\n",
    "            if ros > best_ros:\n",
    "                best_ros = ros\n",
    "                best_param = param\n",
    "                no_improvement_count = 0\n",
    "            else:\n",
    "                no_improvement_count += 1\n",
    "                if no_improvement_count >= max_iter:\n",
    "                    break\n",
    "            if abs(ros - best_ros) < tol:\n",
    "                break\n",
    "    return best_param\n",
    "\n",
    "\n",
    "def Sharpe_gain(Sharpe_val, Roo2_val):\n",
    "    \"\"\"\n",
    "Here: what this function does.\n",
    "Input: \n",
    "    - Sharpe_val: \n",
    "    - Roo2_Val:\n",
    "\n",
    "    Output: \n",
    "    \"\"\"\n",
    "    SR_star = np.sqrt(((Sharpe_val**2)+Roo2_val)/(1-Roo2_val))\n",
    "    return SR_star - Sharpe_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_fun_NN(model, params: dict, X_trn, y_trn, X_vld, y_vld):\n",
    "    \"\"\"\n",
    "Validates a Neural Network to return the best mode.\n",
    "Input: \n",
    "    - model: The model we are validating.\n",
    "    - params: A dictionary of parameters.\n",
    "    - X_trn: Predictors training set.\n",
    "    - y_trn: Dependent variable training set.\n",
    "    - X_vld: Predictors validation set.\n",
    "    - y_vld: Dependent variable validation set.\n",
    "\n",
    "    Output: The best Neural Network model.\n",
    "    \"\"\"\n",
    "    best_ros = None\n",
    "    lst_params = list(ParameterGrid(params))\n",
    "    for param in lst_params:\n",
    "        if best_ros is None:\n",
    "            mod = model(n_layers=param['n_layers'], loss=param['loss'], l1=param['l1'], \n",
    "                            learning_rate=param['learning_rate'], batch_size=param['batch_size'], \n",
    "                            epochs=param['epochs'], random_state=param['random_state'], \n",
    "                            batch_norm=param['batch_norm'], patience=param['patience'], \n",
    "                            verbose=param['verbose'], monitor=param['monitor'])\n",
    "            mod.fit(X_trn, y_trn, X_vld, y_vld)\n",
    "            best_mod = mod\n",
    "            y_pred = mod.predict(X_vld)\n",
    "            best_ros = R_oos(y_vld, y_pred)\n",
    "            best_param = param\n",
    "        else:\n",
    "            mod = model(n_layers=param['n_layers'], loss=param['loss'], l1=param['l1'], \n",
    "                            learning_rate=param['learning_rate'], batch_size=param['batch_size'], \n",
    "                            epochs=param['epochs'], random_state=param['random_state'], \n",
    "                            batch_norm=param['batch_norm'], patience=param['patience'], \n",
    "                            verbose=param['verbose'], monitor=param['monitor'])\n",
    "            mod.fit(X_trn, y_trn, X_vld, y_vld)\n",
    "            y_pred = mod.predict(X_vld)\n",
    "            ros = R_oos(y_vld, y_pred)\n",
    "            if ros > best_ros:\n",
    "                best_ros = ros\n",
    "                best_mod = mod\n",
    "                best_param = param\n",
    "    return best_mod\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - OLS(-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Characteristics of OLS-3\n",
    "OLS-3 includes:\n",
    "\n",
    "* Market size = 'mvel1' \n",
    "* Book-to-Market = 'bm'\n",
    "* Momentum = 'mom1m', 'mom6m', 'mom12m', 'mom36m'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictors needed for the OLS-3 in a seperate file\n",
    "X_3pred = X[['mvel1', 'bm', 'mom1m', 'mom6m', 'mom12m', 'mom36m']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expanding_regression_OLS(Dependent, Predictors, stock_weights, loss = 'OLS', initial_train_years = 18, validation_years = 12, test_years = 1):\n",
    "    \"\"\"\n",
    "Function that runs OLS with expanding window.\n",
    "Input: \n",
    "    - Dependent: Dependent variable data\n",
    "    - Predictors: Independent variables data\n",
    "    - stock_weights: The weights of a stock as percentage of portfolio.\n",
    "    - loss: Specify if you want to use 'OLS' loss, or 'Huber' loss\n",
    "    - initial_train_years: Number of initial training years. (Default is 18)\n",
    "    - validation_years: Number of years for the validation set. (Default is 12)\n",
    "    - test_years: Number of years for the test set. (Default is 1)\n",
    "\n",
    "    Output: Out of sample R-squared.\n",
    "    \"\"\"\n",
    "    # Initialize lists to store values.\n",
    "    r_port_difference_list = []\n",
    "    r_port_actual_list =[]\n",
    "    iterations_Roo2 = []\n",
    "\n",
    "    # List of 1957-2016\n",
    "    years = Dependent.index.year.unique()\n",
    "    start_gen = time.time()\n",
    "\n",
    "    # Loop for expanding window.\n",
    "    for i in range(len(years) - initial_train_years - validation_years):\n",
    "        start = time.time()\n",
    "        iter_difference_list = []\n",
    "        iter_actual_list = []\n",
    "        \n",
    "        start_year = years[i]\n",
    "        end_train_year = start_year + initial_train_years  # 18 years of training and increasing with 1 year every iteration\n",
    "        end_validation_year = end_train_year + validation_years  # 12 years of validation\n",
    "        end_test_year = end_validation_year + test_years  # 1 year of test\n",
    "\n",
    "        # Creating training, validation and test sets.\n",
    "        X_train = Predictors[(Predictors.index.year < end_train_year)]\n",
    "        X_test = Predictors[(Predictors.index.year >= end_validation_year) & (Predictors.index.year < end_test_year)]\n",
    "        y_train = Dependent[(Dependent.index.year < end_train_year)].values.ravel()\n",
    "        y_test = Dependent[(Dependent.index.year >= end_validation_year) & (Dependent.index.year < end_test_year)].values.ravel()\n",
    "\n",
    "        # Specifies which loss function to use.    \n",
    "        if loss == 'OLS':\n",
    "            model = LinearRegression()\n",
    "        elif loss == 'Huber':\n",
    "            model = HuberRegressor(epsilon = 99.9) # Set the epsilon to 99.9%.\n",
    "        else:\n",
    "            raise ValueError(\"Invalid loss function. Use OLS or Huber.\")\n",
    "        \n",
    "        # Training the model\n",
    "        OLS3 = model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict returns at stock level\n",
    "        r_stock_pred = OLS3.predict(X_test).reshape(-1)\n",
    "        \n",
    "        # Gets weights from current testing year\n",
    "        weights_test = stock_weights.loc[str(end_validation_year)]\n",
    "        # Initialize dataframe to store predicted and actual returns\n",
    "        r_portfolio = pd.DataFrame(index=weights_test.index, columns=['return_test', 'return_pred'])\n",
    "        \n",
    "        # Calculate monthly return predicted and actual \n",
    "        for month in range(1, 13):\n",
    "            start_index = (month - 1) * weights_test.shape[0] // 12  \n",
    "            end_index = month * weights_test.shape[0] // 12\n",
    "            month_weights = weights_test.iloc[start_index:end_index]\n",
    "            month_y_test = y_test[start_index:end_index]\n",
    "            month_y_pred = r_stock_pred[start_index:end_index]\n",
    "            # Calculate weighted average return for the month\n",
    "            return_test = np.sum(month_weights['weight'] * month_y_test)\n",
    "            return_pred = np.sum(month_weights['weight'] * month_y_pred)\n",
    "            \n",
    "            # Directly store the monthly values in the lists\n",
    "            r_port_difference_list.append((return_test - return_pred)**2)\n",
    "            r_port_actual_list.append(return_test**2)\n",
    "            iter_difference_list.append((return_test - return_pred)**2)\n",
    "            iter_actual_list.append(return_test**2)\n",
    "    \n",
    "        iter_Roo2 = R_oos(iter_difference_list,  iter_actual_list)\n",
    "        iterations_Roo2.append(iter_Roo2)\n",
    "        \n",
    "        stop = time.time()\n",
    "        print(f'Iteration number {i+1} finished, Running time {stop-start}, Roo2 iteration {i+1} = {iter_Roo2}')\n",
    "        \n",
    "    stop_gen = time.time()\n",
    "    print(f'TOTAL RUNNING TIME = {stop_gen-start_gen}.')\n",
    "    \n",
    "    # Calculate Roos\n",
    "    Model_Roos = R_oos(r_port_difference_list, r_port_actual_list)\n",
    "    Iterations_average_Roos = np.mean(iterations_Roo2)\n",
    "    \n",
    "    print('-'*46+'RESULTS'+'-'*46)\n",
    "    print(f'OverallModel Roo2: {Model_Roos} || Average of Single Iterations Roo2: {Iterations_average_Roos}')\n",
    "        \n",
    "    return Model_Roos, Iterations_average_Roos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - OLS-3 without Huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OUT-OF-SAMPLE R^2 for OLS-3\n",
    "OLS_Roos, OLS_iteravg_Roos = expanding_regression_OLS(y,X_3pred,stock_weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - OLS-3 with Huber loss function implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OUT-OF-SAMPLE R^2 for OLS-3 with Huber Loss function\n",
    "OLS_3pred_Roos_H, OLS_iteravg_Roos = expanding_regression_OLS(y, X_3pred,stock_weights=weights, loss = 'Huber')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Dimension Reduction: PCR and PLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - PCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcr(Dependent, Predictors, stock_weights, initial_train_years=18, validation_years=12, test_years=1):\n",
    "    \"\"\"\n",
    "Function that runs PCR with expanding window.\n",
    "Input: \n",
    "    - Dependent: Dependent variable data\n",
    "    - Predictors: Independent variables data\n",
    "    - stock_weights: The weights of a stock as percentage of portfolio\n",
    "    - initial_train_years: Number of initial training years. (Default is 18)\n",
    "    - validation_years: Number of years for the validation set. (Default is 12)\n",
    "    - test_years: Number of years for the test set. (Default is 1)\n",
    "\n",
    "    Output: Out of sample R-squared.\n",
    "    \"\"\"\n",
    "    # Lists to save outcomes.\n",
    "    component_counts = []\n",
    "    r_port_difference_list = []\n",
    "    r_port_actual_list = []\n",
    "    iterations_Roo2 = []\n",
    "\n",
    "    yrs = Dependent.index.year.unique() # List with all the years. (1957-2016)\n",
    "    start_gen = time.time()\n",
    "    n_components_list = range(1, 7) # To determine the number of components that are tested.\n",
    "    best_components = None # Initialize and later save the best amount of components.\n",
    "    best_r2 = -np.inf  # Initialize with negative infinity to find the maximum R-squared\n",
    "\n",
    "    # Expanding window.\n",
    "    for i in range(len(yrs) - initial_train_years - validation_years):\n",
    "        start = time.time()\n",
    "        iter_difference_list = []\n",
    "        iter_actual_list = []\n",
    "        \n",
    "        start_year = yrs[i]\n",
    "        end_train_year = start_year + initial_train_years  # 18 years of training and increasing with 1 year every iteration\n",
    "        end_validation_year = end_train_year + validation_years  # 12 years of validation\n",
    "        end_test_year = end_validation_year + test_years  # 1 year of test\n",
    "\n",
    "        # Creating training, validation and test sets.\n",
    "        X_train = Predictors[(Predictors.index.year < end_train_year)]\n",
    "        X_test = Predictors[(Predictors.index.year >= end_validation_year) & (Predictors.index.year < end_test_year)]\n",
    "        X_val = Predictors[(Predictors.index.year >= end_train_year) & (Predictors.index.year < end_validation_year)]\n",
    "        y_train = Dependent[(Dependent.index.year < end_train_year)].values.ravel()\n",
    "        y_test = Dependent[(Dependent.index.year >= end_validation_year) & (Dependent.index.year < end_test_year)].values.ravel()\n",
    "        y_val = Dependent[(Dependent.index.year >= end_train_year) & (Dependent.index.year < end_validation_year)].values.ravel()\n",
    "\n",
    "        # Testing the different components in PCA.\n",
    "        for n_component in n_components_list:\n",
    "\n",
    "            pca = PCA(n_components=n_component)\n",
    "            X_train_pca = pca.fit_transform(X_train) \n",
    "            X_val_pca = pca.transform(X_val)\n",
    "\n",
    "            # Fit Linear Regression on the training set\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_train_pca, y_train)\n",
    "\n",
    "            # Predict on the validation set\n",
    "            y_val_pred = model.predict(X_val_pca)\n",
    "            r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "            # Update best components if the current number of components yields a higher R-squared\n",
    "            if r2 > best_r2:\n",
    "                best_r2 = r2\n",
    "                best_components = n_component\n",
    "\n",
    "        # Save the best number of components to the list\n",
    "        component_counts.append(best_components)\n",
    "\n",
    "        # Use the best number of components to fit the final model on the combined training and validation sets\n",
    "        best_pca = PCA(n_components=best_components)\n",
    "        X_train_pca = best_pca.fit_transform(X_train)\n",
    "        X_test_pca = best_pca.transform(X_test)\n",
    "        \n",
    "        # Best Model\n",
    "        PCASP500 = LinearRegression()\n",
    "        PCASP500.fit(X_train_pca, y_train)\n",
    "\n",
    "        # Predict returns at the stock level\n",
    "        r_stock_pred = PCASP500.predict(X_test_pca)\n",
    "        \n",
    "        # Gets weights from current testing year\n",
    "        weights_test = stock_weights.loc[str(end_validation_year)]\n",
    "        # Initialize dataframe to store predicted and actual returns\n",
    "        r_portfolio = pd.DataFrame(index=weights_test.index, columns=['return_test', 'return_pred'])\n",
    "        \n",
    "        # Calculate monthly return predicted and actual \n",
    "        for month in range(1, 13):\n",
    "            start_index = (month - 1) * weights_test.shape[0] // 12  \n",
    "            end_index = month * weights_test.shape[0] // 12\n",
    "            month_weights = weights_test.iloc[start_index:end_index]\n",
    "            month_y_test = y_test[start_index:end_index]\n",
    "            month_y_pred = r_stock_pred[start_index:end_index]\n",
    "            # Calculate weighted average return for the month\n",
    "            return_test = np.sum(month_weights['weight'] * month_y_test)\n",
    "            return_pred = np.sum(month_weights['weight'] * month_y_pred)\n",
    "\n",
    "            # Directly store the monthly values in the lists\n",
    "            r_port_difference_list.append((return_test - return_pred)**2)\n",
    "            r_port_actual_list.append(return_test**2)\n",
    "            iter_difference_list.append((return_test - return_pred)**2)\n",
    "            iter_actual_list.append(return_test**2)\n",
    "        \n",
    "        iter_Roo2 = R_oos(iter_difference_list,  iter_actual_list)\n",
    "        iterations_Roo2.append(iter_Roo2)\n",
    "        \n",
    "        stop = time.time()\n",
    "        print(f'Iteration number {i+1} finished, Running time {stop-start}, Roo2 iteration {i+1} = {iter_Roo2}')\n",
    "        \n",
    "    stop_gen = time.time()\n",
    "    print(f'TOTAL RUNNING TIME = {stop_gen-start_gen}.')\n",
    "    \n",
    "    # Calculate Roos\n",
    "    Model_Roos = R_oos(r_port_difference_list, r_port_actual_list)\n",
    "    Iterations_average_Roos = np.mean(iterations_Roo2)\n",
    "    \n",
    "    print('-'*46+'RESULTS'+'-'*46)\n",
    "    print(f'OverallModel Roo2: {Model_Roos} || Average of Single Iterations Roo2: {Iterations_average_Roos}')\n",
    "        \n",
    "    return Model_Roos, Iterations_average_Roos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Out Of Sample R_squared\n",
    "PCR_Roos, PCR_iteravg_Roos = pcr(Dependent=y, Predictors=X, stock_weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - PLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pls(Dependent, Predictors, stock_weights, initial_train_years=18, validation_years=12, test_years=1):\n",
    "    \"\"\"\n",
    "Function that runs PLS with expanding window.\n",
    "Input: \n",
    "    - Dependent: Dependent variable data\n",
    "    - Predictors: Independent variables data\n",
    "    - stock_weights: The weights of a stock as percentage of portfolio\n",
    "    - initial_train_years: Number of initial training years. (Default is 18)\n",
    "    - validation_years: Number of years for the validation set. (Default is 12)\n",
    "    - test_years: Number of years for the test set. (Default is 1)\n",
    "\n",
    "    Output: Out of sample R-squared.\n",
    "    \"\"\" \n",
    "    # # Initalize to store r-squared for portfolio..\n",
    "    r_port_difference_list = []\n",
    "    r_port_actual_list =[]\n",
    "    component_counts = [] # Initialize to save number of components.\n",
    "    iterations_Roo2 = []\n",
    "\n",
    "    years = Predictors.index.year.unique()#List of years (1957-2016)\n",
    "    start_gen = time.time()\n",
    "    n_components_list = range(1, 7) # To determine the number of components that are tested.\n",
    "    best_components = None # Initialize and later save the best amount of components.\n",
    "    best_r2 = -np.inf  # Initialize with negative infinity to find the maximum R-squared\n",
    "\n",
    "    for i in range(len(years) - initial_train_years - validation_years): \n",
    "        start = time.time()\n",
    "        iter_difference_list = []\n",
    "        iter_actual_list = []\n",
    "        \n",
    "        start_year = years[i]\n",
    "        end_train_year = start_year + initial_train_years  # 18 years of training and increasing with 1 year every iteration\n",
    "        end_validation_year = end_train_year + validation_years  # 12 years of validation\n",
    "        end_test_year = end_validation_year + test_years  # 1 year of test\n",
    "\n",
    "        # Creating training, validation and test sets.\n",
    "        X_train = Predictors[(Predictors.index.year < end_train_year)]\n",
    "        X_test = Predictors[(Predictors.index.year >= end_validation_year) & (Predictors.index.year < end_test_year)]\n",
    "        X_val = Predictors[(Predictors.index.year >= end_train_year) & (Predictors.index.year < end_validation_year)]\n",
    "        y_train = Dependent[(Dependent.index.year < end_train_year)].values.ravel()\n",
    "        y_test = Dependent[(Dependent.index.year >= end_validation_year) & (Dependent.index.year < end_test_year)].values.ravel()\n",
    "        y_val = Dependent[(Dependent.index.year >= end_train_year) & (Dependent.index.year < end_validation_year)].values.ravel()\n",
    "\n",
    "        # Testing the different components in PLS.\n",
    "        for n_component in n_components_list:\n",
    "\n",
    "            # Train the model once on the training set\n",
    "            pls = PLSRegression(n_components=n_component)\n",
    "            pls.fit(X_train, y_train) \n",
    "\n",
    "           # Predict on the validation set\n",
    "            y_val_pred = pls.predict(X_val)\n",
    "            r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "            # Update best components if the current number of components yields a higher R-squared\n",
    "            if r2 > best_r2:\n",
    "                best_r2 = r2\n",
    "                best_components = n_component\n",
    "\n",
    "        # Save the best number of components to the list\n",
    "        component_counts.append(best_components)\n",
    "\n",
    "        # Use the best number of components to fit the final model \n",
    "        best_pls = PLSRegression(n_components=best_components)\n",
    "        best_pls.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the final model on the test set\n",
    "        r_stock_pred = best_pls.predict(X_test)\n",
    "        \n",
    "        # Gets weights from current testing year\n",
    "        weights_test = stock_weights.loc[str(end_validation_year)]\n",
    "        # Initialize dataframe to store predicted and actual returns\n",
    "        r_portfolio = pd.DataFrame(index=weights_test.index, columns=['return_test', 'return_pred'])\n",
    "        \n",
    "        # Calculate monthly return predicted and actual \n",
    "        for month in range(1, 13):\n",
    "            start_index = (month - 1) * weights_test.shape[0] // 12  \n",
    "            end_index = month * weights_test.shape[0] // 12\n",
    "            month_weights = weights_test.iloc[start_index:end_index]\n",
    "            month_y_test = y_test[start_index:end_index]\n",
    "            month_y_pred = r_stock_pred[start_index:end_index]\n",
    "            \n",
    "            # Calculate weighted average return for the month\n",
    "            return_test = np.sum(month_weights['weight'] * month_y_test)\n",
    "            return_pred = np.sum(month_weights['weight'] * month_y_pred)\n",
    "\n",
    "            # Directly store the monthly values in the lists\n",
    "            r_port_difference_list.append((return_test - return_pred)**2)\n",
    "            r_port_actual_list.append(return_test**2)\n",
    "            iter_difference_list.append((return_test - return_pred)**2)\n",
    "            iter_actual_list.append(return_test**2)\n",
    "        \n",
    "        iter_Roo2 = R_oos(iter_difference_list,  iter_actual_list)\n",
    "        iterations_Roo2.append(iter_Roo2)\n",
    "        \n",
    "        stop = time.time()\n",
    "        print(f'Iteration number {i+1} finished, Running time {stop-start}, Roo2 iteration {i+1} = {iter_Roo2}')\n",
    "        \n",
    "    stop_gen = time.time()\n",
    "    print(f'TOTAL RUNNING TIME = {stop_gen-start_gen}.')\n",
    "    \n",
    "    # Calculate Roos\n",
    "    Model_Roos = R_oos(r_port_difference_list, r_port_actual_list)\n",
    "    Iterations_average_Roos = np.mean(iterations_Roo2)\n",
    "    \n",
    "    print('-'*46+'RESULTS'+'-'*46)\n",
    "    print(f'OverallModel Roo2: {Model_Roos} || Average of Single Iterations Roo2: {Iterations_average_Roos}')\n",
    "        \n",
    "    return Model_Roos, Iterations_average_Roos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs PLS and saves the results\n",
    "pls_Roos, pls_iteravg_Roos = pls(Dependent=y, Predictors=X, stock_weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Elastic Net & Lasso & Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elastic Net -> l1_ratio=0.5\n",
    "Ridge -> l1_ratio=0\n",
    "Lasso -> l1_ratio=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ENet(Dependent, Predictors, stock_weights, initial_train_years=18, validation_years=12, test_years=1):\n",
    "    \"\"\"\n",
    "Function that runs Elastic Net with expanding window.\n",
    "Input: \n",
    "    - Dependent: Dependent variable data\n",
    "    - Predictors: Independent variables data\n",
    "    - stock_weights: The weights of a stock as percentage of portfolio\n",
    "    - initial_train_years: Number of initial training years. (Default is 18)\n",
    "    - validation_years: Number of years for the validation set. (Default is 12)\n",
    "    - test_years: Number of years for the test set. (Default is 1)\n",
    "\n",
    "    Output: Out of sample R-squared.\n",
    "    \"\"\"\n",
    "    # Initalize to store r-squared for portfolio.\n",
    "    r_port_difference_list = []\n",
    "    r_port_actual_list = []\n",
    "    iterations_Roo2 = []\n",
    "    # Tested tuning parameters\n",
    "    tuning_par = {\n",
    "        \"alpha\": np.linspace(1e-1, 1e-4, num=10),\n",
    "        \"l1_ratio\": [0.5], \"tol\":[1e-2]\n",
    "    } \n",
    "    \n",
    "    # All the years(1957-2016)\n",
    "    yrs = Dependent.index.year.unique()\n",
    "    start_gen = time.time()\n",
    "    \n",
    "    # Now the model runs for every time of the 30 splits and for every possible combination of the tuning parameters.\n",
    "    for i in range(len(yrs) - initial_train_years - validation_years):\n",
    "        start = time.time()\n",
    "        iter_difference_list = []\n",
    "        iter_actual_list = []\n",
    "        \n",
    "        start_year = yrs[i]\n",
    "        end_train_year = start_year + initial_train_years  # 18 years of training and increasing with 1 year every iteration\n",
    "        end_validation_year = end_train_year + validation_years  # 12 years of validation\n",
    "        end_test_year = end_validation_year + test_years  # 1 year of test\n",
    "\n",
    "        # Creating training, validation and test sets.\n",
    "        X_train = Predictors[(Predictors.index.year < end_train_year)]\n",
    "        X_test = Predictors[(Predictors.index.year >= end_validation_year) & (Predictors.index.year < end_test_year)]\n",
    "        X_val = Predictors[(Predictors.index.year >= end_train_year) & (Predictors.index.year < end_validation_year)]\n",
    "        y_train = Dependent[(Dependent.index.year < end_train_year)].values.ravel()\n",
    "        y_test = Dependent[(Dependent.index.year >= end_validation_year) & (Dependent.index.year < end_test_year)].values.ravel()\n",
    "        y_val = Dependent[(Dependent.index.year >= end_train_year) & (Dependent.index.year < end_validation_year)].values.ravel()\n",
    "        \n",
    "        # This part runs the tuning to find the best combination of the tuning parameters for every split\n",
    "        best_par = val_fun(ElasticNet, params=tuning_par, X_trn=X_train, y_trn=y_train, X_vld=X_val, y_vld=y_val)\n",
    "        \n",
    "        # Now we test the model\n",
    "        ENet_SP500 = ElasticNet(alpha=best_par['alpha'], l1_ratio=best_par['l1_ratio']).fit(X_train, y_train)\n",
    "\n",
    "        # Calculate R_squared        \n",
    "        r_stock_pred = ENet_SP500.predict(X_test)\n",
    "        \n",
    "        # Gets weights from current testing year\n",
    "        weights_test = stock_weights.loc[str(end_validation_year)]\n",
    "        # Initialize dataframe to store predicted and actual returns\n",
    "        r_portfolio = pd.DataFrame(index=weights_test.index, columns=['return_test', 'return_pred'])\n",
    "        \n",
    "        # Calculate monthly return predicted and actual \n",
    "        for month in range(1, 13):\n",
    "            start_index = (month - 1) * weights_test.shape[0] // 12  \n",
    "            end_index = month * weights_test.shape[0] // 12\n",
    "            month_weights = weights_test.iloc[start_index:end_index]\n",
    "            month_y_test = y_test[start_index:end_index]\n",
    "            month_y_pred = r_stock_pred[start_index:end_index]\n",
    "            \n",
    "            # Calculate weighted average return for the month\n",
    "            return_test = np.sum(month_weights['weight'] * month_y_test)\n",
    "            return_pred = np.sum(month_weights['weight'] * month_y_pred)\n",
    "\n",
    "            # Directly store the monthly values in the lists\n",
    "            r_port_difference_list.append((return_test - return_pred)**2)\n",
    "            r_port_actual_list.append(return_test**2)\n",
    "            iter_difference_list.append((return_test - return_pred)**2)\n",
    "            iter_actual_list.append(return_test**2)\n",
    "        \n",
    "        iter_Roo2 = R_oos(iter_difference_list,  iter_actual_list)\n",
    "        iterations_Roo2.append(iter_Roo2)\n",
    "        \n",
    "        stop = time.time()\n",
    "        print(f'Iteration number {i+1} finished, Running time {stop-start}, Roo2 iteration {i+1} = {iter_Roo2}')\n",
    "        \n",
    "    stop_gen = time.time()\n",
    "    print(f'TOTAL RUNNING TIME = {stop_gen-start_gen}.')\n",
    "    \n",
    "    # Calculate Roos\n",
    "    Model_Roos = R_oos(r_port_difference_list, r_port_actual_list)\n",
    "    Iterations_average_Roos = np.mean(iterations_Roo2)\n",
    "    \n",
    "    print('-'*46+'RESULTS'+'-'*46)\n",
    "    print(f'OverallModel Roo2: {Model_Roos} || Average of Single Iterations Roo2: {Iterations_average_Roos}')\n",
    "        \n",
    "    return Model_Roos, Iterations_average_Roos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25721887452371794"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Runs PLS and saves the results\n",
    "ENet_Roos, ENet_iteravg_Roos = ENet(Dependent=y, Predictors=X, stock_weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso (not adjusted to newest code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lasso(Dependent, Predictors, stock_weights, initial_train_years=18, validation_years=12, test_years=1):\n",
    "    \"\"\"\n",
    "Function that runs Lasso Regression with expanding window.\n",
    "Input: \n",
    "    - Dependent: Dependent variable data\n",
    "    - Predictors: Independent variables data\n",
    "    - stock_weights: The weights of a stock as percentage of portfolio\n",
    "    - initial_train_years: Number of initial training years. (Default is 18)\n",
    "    - validation_years: Number of years for the validation set. (Default is 12)\n",
    "    - test_years: Number of years for the test set. (Default is 1)\n",
    "\n",
    "    Output: Out of sample R-squared.\n",
    "\"\"\"\n",
    "    # All the years(1957-2016)\n",
    "    yrs = Dependent.index.year.unique()\n",
    "    # Initalize to store r-squared for portfolio.\n",
    "    r_port_difference_list = []\n",
    "    r_port_actual_list = []\n",
    "    # Tested tuning parameters\n",
    "    tuning_par = {\n",
    "        \"alpha\": np.linspace(1e-1, 1e-4, num=10),\n",
    "        \"l1_ratio\": [1], \"tol\":[1e-2]\n",
    "    } \n",
    "    \n",
    "    # Now the model runs for every time of the 30 splits and for every possible combination of the tuning parameters.\n",
    "    for i in range(len(yrs) - initial_train_years - validation_years):\n",
    "        start_year = yrs[i]\n",
    "        end_train_year = start_year + initial_train_years  # 18 years of training and increasing with 1 year every iteration\n",
    "        end_validation_year = end_train_year + validation_years  # 12 years of validation\n",
    "        end_test_year = end_validation_year + test_years  # 1 year of test\n",
    "\n",
    "        # Creating training, validation and test sets.\n",
    "        X_train = Predictors[(Predictors.index.year < end_train_year)]\n",
    "        X_test = Predictors[(Predictors.index.year >= end_validation_year) & (Predictors.index.year < end_test_year)]\n",
    "        X_val = Predictors[(Predictors.index.year >= end_train_year) & (Predictors.index.year < end_validation_year)]\n",
    "        y_train = Dependent[(Dependent.index.year < end_train_year)].values.ravel()\n",
    "        y_test = Dependent[(Dependent.index.year >= end_validation_year) & (Dependent.index.year < end_test_year)].values.ravel()\n",
    "        y_val = Dependent[(Dependent.index.year >= end_train_year) & (Dependent.index.year < end_validation_year)].values.ravel()\n",
    "        \n",
    "        # This part runs the tuning to find the best combination of the tuning parameters for every split\n",
    "        best_par = val_fun(ElasticNet, params=tuning_par, X_trn=X_train, y_trn=y_train, X_vld=X_val, y_vld=y_val)\n",
    "        \n",
    "        # Now we test the model\n",
    "        LAS_SP500 = ElasticNet(alpha=best_par['alpha'], l1_ratio=best_par['l1_ratio']).fit(X_train, y_train)\n",
    "\n",
    "        # Calculate R_squared        \n",
    "        r_stock_pred = LAS_SP500.predict(X_test)\n",
    "        \n",
    "        # Gets weights from current testing year\n",
    "        weights_test = stock_weights.loc[str(end_validation_year)]\n",
    "        # Initialize dataframe to store predicted and actual returns\n",
    "        r_portfolio = pd.DataFrame(index=weights_test.index, columns=['return_test', 'return_pred'])\n",
    "        \n",
    "        # Calculate monthly return predicted and actual \n",
    "        for month in range(1, 13):\n",
    "            start_index = (month - 1) * weights_test.shape[0] // 12  \n",
    "            end_index = month * weights_test.shape[0] // 12\n",
    "            month_weights = weights_test.iloc[start_index:end_index]\n",
    "            month_y_test = y_test[start_index:end_index]\n",
    "            month_y_pred = r_stock_pred[start_index:end_index]\n",
    "            # Store the results in a DataFrame\n",
    "            r_portfolio.loc[f'{end_validation_year}-{month:02d}', ['return_test', 'return_pred']] = np.sum(month_weights['weight'] * month_y_test), np.sum(month_weights['weight'] * month_y_pred) \n",
    "\n",
    "        # Store numerator and denominator to calculate out of sample R-Squared\n",
    "        r_port_difference_list.extend(((r_portfolio['return_test']-r_portfolio['return_pred'])**2).tolist())\n",
    "        r_port_actual_list.extend(((r_portfolio['return_test'])**2).tolist())\n",
    "    \n",
    "    # Calculate Roos\n",
    "    Model_Roos = R_oos(r_port_difference_list, r_port_actual_list)\n",
    "\n",
    "    return Model_Roos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25721887452371794"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso results\n",
    "Lasso_score = Lasso(Dependent=y,Predictors=X,stock_weights=weights) \n",
    "Lasso_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge (not adjusted to newest code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ridge(Dependent, Predictors, stock_weights, initial_train_years=18, validation_years=12, test_years=1):\n",
    "    \"\"\"\n",
    "Function that runs Ridge Regression with expanding window.\n",
    "Input: \n",
    "    - Dependent: Dependent variable data\n",
    "    - Predictors: Independent variables data\n",
    "    - stock_weights: The weights of a stock as percentage of portfolio\n",
    "    - initial_train_years: Number of initial training years. (Default is 18)\n",
    "    - validation_years: Number of years for the validation set. (Default is 12)\n",
    "    - test_years: Number of years for the test set. (Default is 1)\n",
    "\n",
    "    Output: Out of sample R-squared.\n",
    "\"\"\"\n",
    "    # All the years(1957-2016)\n",
    "    yrs = Dependent.index.year.unique()\n",
    "    # Initalize to store r-squared for portfolio.\n",
    "    r_port_difference_list = []\n",
    "    r_port_actual_list = []\n",
    "    # Tested tuning parameters\n",
    "    tuning_par = {\n",
    "        \"alpha\": np.linspace(1e-1, 1e-4, num=10),\n",
    "        \"l1_ratio\": [0], \"tol\":[1e-2]\n",
    "    } \n",
    "    \n",
    "    # Now the model runs for every time of the 30 splits and for every possible combination of the tuning parameters.\n",
    "    for i in range(len(yrs) - initial_train_years - validation_years):\n",
    "        start_year = yrs[i]\n",
    "        end_train_year = start_year + initial_train_years  # 18 years of training and increasing with 1 year every iteration\n",
    "        end_validation_year = end_train_year + validation_years  # 12 years of validation\n",
    "        end_test_year = end_validation_year + test_years  # 1 year of test\n",
    "\n",
    "        # Creating training, validation and test sets.\n",
    "        X_train = Predictors[(Predictors.index.year < end_train_year)]\n",
    "        X_test = Predictors[(Predictors.index.year >= end_validation_year) & (Predictors.index.year < end_test_year)]\n",
    "        X_val = Predictors[(Predictors.index.year >= end_train_year) & (Predictors.index.year < end_validation_year)]\n",
    "        y_train = Dependent[(Dependent.index.year < end_train_year)].values.ravel()\n",
    "        y_test = Dependent[(Dependent.index.year >= end_validation_year) & (Dependent.index.year < end_test_year)].values.ravel()\n",
    "        y_val = Dependent[(Dependent.index.year >= end_train_year) & (Dependent.index.year < end_validation_year)].values.ravel()\n",
    "        \n",
    "        # This part runs the tuning to find the best combination of the tuning parameters for every split\n",
    "        best_par = val_fun(ElasticNet, params=tuning_par, X_trn=X_train, y_trn=y_train, X_vld=X_val, y_vld=y_val)\n",
    "        \n",
    "        # Now we test the model\n",
    "        RID_SP500 = ElasticNet(alpha=best_par['alpha'], l1_ratio=best_par['l1_ratio']).fit(X_train, y_train)\n",
    "\n",
    "        # Calculate R_squared        \n",
    "        r_stock_pred = RID_SP500.predict(X_test)\n",
    "        \n",
    "        # Gets weights from current testing year\n",
    "        weights_test = stock_weights.loc[str(end_validation_year)]\n",
    "        # Initialize dataframe to store predicted and actual returns\n",
    "        r_portfolio = pd.DataFrame(index=weights_test.index, columns=['return_test', 'return_pred'])\n",
    "        \n",
    "        # Calculate monthly return predicted and actual \n",
    "        for month in range(1, 13):\n",
    "            start_index = (month - 1) * weights_test.shape[0] // 12  \n",
    "            end_index = month * weights_test.shape[0] // 12\n",
    "            month_weights = weights_test.iloc[start_index:end_index]\n",
    "            month_y_test = y_test[start_index:end_index]\n",
    "            month_y_pred = r_stock_pred[start_index:end_index]\n",
    "            # Store the results in a DataFrame\n",
    "            r_portfolio.loc[f'{end_validation_year}-{month:02d}', ['return_test', 'return_pred']] = np.sum(month_weights['weight'] * month_y_test), np.sum(month_weights['weight'] * month_y_pred) \n",
    "\n",
    "        # Store numerator and denominator to calculate out of sample R-Squared\n",
    "        r_port_difference_list.extend(((r_portfolio['return_test']-r_portfolio['return_pred'])**2).tolist())\n",
    "        r_port_actual_list.extend(((r_portfolio['return_test'])**2).tolist())\n",
    "    \n",
    "    # Calculate Roos\n",
    "    Model_Roos = R_oos(r_port_difference_list, r_port_actual_list)\n",
    "\n",
    "    return Model_Roos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25721887452371794"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results Ridge regression\n",
    "Ridge_score = Ridge(Dependent=y,Predictors=X,stock_weights=weights) \n",
    "Ridge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Huber-Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huber-Loss-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_loss(y_val, y_pred, delta):\n",
    "    \"\"\"\n",
    "Function that ...\n",
    "Input: \n",
    "    - y_val: ...\n",
    "    - y_pred: ...\n",
    "    - delta: ...\n",
    "\n",
    "    Output: ...\n",
    "\"\"\"\n",
    "    error = y_val - y_pred\n",
    "    is_small_error = np.abs(error) <= delta\n",
    "    squared_loss = 0.5 * (error ** 2)\n",
    "    linear_loss = delta * (np.abs(error) - 0.5 * delta)\n",
    "    return np.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_fun_with_huber(model, params: dict, X_trn, y_trn, X_vld, y_vld):\n",
    "    \"\"\"\n",
    "Function that ...\n",
    "Input: \n",
    "    - model: ...\n",
    "    - params: ...\n",
    "    - X_trn: ...\n",
    "    - y_trn: ...\n",
    "    - X_vld ...\n",
    "    - y_vld ...\n",
    "\n",
    "    Output: ...\n",
    "\"\"\"\n",
    "    best_ros = None\n",
    "    lst_params = list(ParameterGrid(params))\n",
    "    for param in lst_params:\n",
    "        if best_ros == None:\n",
    "            mod = model().set_params(**param).fit(X_trn, y_trn)\n",
    "            y_pred = mod.predict(X_vld)\n",
    "            smallest_loss = huber(y_vld, y_pred, xi=.999)\n",
    "            best_param = param\n",
    "        else:\n",
    "            mod = model().set_params(**param).fit(X_trn, y_trn)\n",
    "            y_pred = mod.predict(X_vld)\n",
    "            loss = huber(y_vld, y_pred, xi=0.999)\n",
    "            if loss < smallest_loss:\n",
    "                smallest_loss = loss\n",
    "                best_param = param\n",
    "    return best_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of the Huber loss with the accelarated proximal algorithm (APG), as explained in the appendix of the paper. \n",
    "The Accelerated Proximal Gradient Method should be iniciated with theta=0 however we didn't managed to make it work therefore we use a random state to set inicial values for theta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mse(actual, predicted):\n",
    "    actual, predicted = np.array(actual).flatten(), np.array(predicted).flatten()\n",
    "    resid = actual - predicted\n",
    "    return np.mean(resid**2)\n",
    "\n",
    "# huber objective function\n",
    "def huber(actual, predicted, xi):\n",
    "    actual, predicted = np.array(actual).flatten(), np.array(predicted).flatten()\n",
    "    resid = actual - predicted\n",
    "    huber_loss = np.where(np.abs(resid)<=xi, resid**2, 2*xi*np.abs(resid)-xi**2)\n",
    "    return np.mean(huber_loss)\n",
    "\n",
    "# gradient of mse\n",
    "def grad_mse(X, y, theta):\n",
    "    K = X.shape[1]\n",
    "    X = np.array(X)\n",
    "    N = len(y)\n",
    "    y = np.array(y).reshape((N,1))\n",
    "    theta = np.array(theta).reshape((K,1))\n",
    "    return (X.T @ (y - X@theta))/N\n",
    "\n",
    "# gradient of huber loss\n",
    "def grad_huber(X, y, theta, xi):\n",
    "    K = X.shape[1]\n",
    "    X = np.array(X)\n",
    "    N = len(y)\n",
    "    y = np.array(y).reshape((N,1))\n",
    "    theta = np.array(theta).reshape((K,1))\n",
    "    resid = y - X@theta\n",
    "    ind_m = np.where(np.abs(resid)<=xi)\n",
    "    ind_u = np.where(resid>xi)\n",
    "    ind_l = np.where(resid< -xi)\n",
    "    try:\n",
    "        grad_m = X[ind_m].T @ (y[ind_m] - X[ind_m]@theta)\n",
    "    except:\n",
    "        grad_m = np.zeros((K,1))\n",
    "    try:\n",
    "        grad_u = 2*xi* X[ind_u].T@np.ones((len(ind_u[0]),1))\n",
    "    except:\n",
    "        grad_u = np.zeros((K,1))\n",
    "    try:\n",
    "        grad_l = -2*xi* X[ind_l].T@np.ones((len(ind_l[0]),1))\n",
    "    except:\n",
    "        grad_l = np.zeros((K,1))\n",
    "    return (grad_m+grad_u+grad_l)/N\n",
    "\n",
    "# proximal operator\n",
    "def prox(theta,lmd,rho,gamma):\n",
    "    return (1/(1+lmd*gamma*rho))*softhred(theta,(1-rho)*gamma*lmd)\n",
    "\n",
    "# soft-thresholding operator\n",
    "def softhred(x,mu):\n",
    "    x = np.where(np.abs(x)<=mu, 0, x)\n",
    "    x = np.where((np.abs(x)>mu) & (x>0), x-mu, x)\n",
    "    x = np.where((np.abs(x)>mu) & (x<0), x+mu, x)\n",
    "    return x\n",
    "\n",
    "# Elastic Net\n",
    "class ENet:\n",
    "    \n",
    "    def __init__(\n",
    "        self, lmd=1, rho=0.5, L=1,\n",
    "        xi=0.99, max_iter=3000, tol=1e-4, loss='huber', random_state=None\n",
    "    ):\n",
    "        self.lmd = lmd\n",
    "        self.rho = rho\n",
    "        self.L = L\n",
    "        self.xi = xi\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.random_state = random_state\n",
    "        if loss not in ['huber','mse']:\n",
    "            raise AttributeError(\n",
    "            f\"The loss should be either 'huber' or 'mse', but {loss} is given\"\n",
    "            )\n",
    "        else:\n",
    "            self.loss = loss\n",
    "            \n",
    "    def set_params(self, **params):\n",
    "        for param in params.keys():\n",
    "            setattr(self, param, params[param])\n",
    "        return self\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        K = X.shape[1]\n",
    "        X = np.array(X)\n",
    "        N = len(y)\n",
    "        y = np.array(y).reshape((N, 1))\n",
    "        gamma = self.L #gamma is the learning rate\n",
    "        # initialize theta\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "            theta = np.random.uniform(size=(K, 1))\n",
    "        else:\n",
    "            theta = np.zeros((K, 1))\n",
    "\n",
    "        for m in range(self.max_iter):\n",
    "            theta_old = theta\n",
    "\n",
    "            if self.loss == 'mse':\n",
    "                theta_bar = theta - gamma * grad_mse(X, y, theta)\n",
    "            else:\n",
    "                theta_bar = theta - gamma * grad_huber(X, y, theta, self.xi)\n",
    "\n",
    "            theta_til = prox(theta_bar, self.lmd, self.rho, gamma)\n",
    "            theta = theta_til + m / (m + 3) * (theta_til - theta)\n",
    "            gamma = gamma\n",
    "\n",
    "            # Check for convergence\n",
    "            if np.sum((theta - theta_old)**2) < np.sum(theta_old**2 * self.tol) or np.sum(np.abs(theta - theta_old)) == 0:\n",
    "                break\n",
    "\n",
    "        self.theta = theta_old\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        return X@self.theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E-Net with Huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ENet_with_huber(Dependent, Predictors, stock_weights, initial_train_years=18, validation_years=12, test_years=1):\n",
    "    \"\"\"\n",
    "Function that runs Elastic Net using Huber Loss function.\n",
    "Input: \n",
    "    - Dependent: Dependent variable data\n",
    "    - Predictors: Independent variables data\n",
    "    - stock_weights: The weights of a stock as percentage of portfolio\n",
    "    - initial_train_years: Number of initial training years. (Default is 18)\n",
    "    - validation_years: Number of years for the validation set. (Default is 12)\n",
    "    - test_years: Number of years for the test set. (Default is 1)\n",
    "\n",
    "    Output: Out of sample R-squared.\n",
    "\"\"\"\n",
    "    # Initalize to store r-squared for portfolio.\n",
    "    r_port_difference_list = []\n",
    "    r_port_actual_list = []\n",
    "    iterations_Roo2 = []\n",
    "    # Tested tuning parameters\n",
    "    tuning_par = {\n",
    "         \"lmd\": np.linspace(1e-1, 1e-4, num=10),\n",
    "        \"rho\": [0.5], \"tol\":[1e-2],'L': np.linspace(1e-1, 1e-4, num=10),'random state':[12308]\n",
    "    \n",
    "    } \n",
    "    # All the years(1957-2016)\n",
    "    yrs = Dependent.index.year.unique()\n",
    "    start_gen = time.time()\n",
    "    \n",
    "    for i in range(len(yrs) - initial_train_years - validation_years):\n",
    "        start = time.time()\n",
    "        iter_difference_list = []\n",
    "        iter_actual_list = []\n",
    "        \n",
    "        start_year = yrs[i]\n",
    "        end_train_year = start_year + initial_train_years\n",
    "        end_validation_year = end_train_year + validation_years\n",
    "        end_test_year = end_validation_year + test_years\n",
    "\n",
    "        X_train = Predictors[(Predictors.index.year < end_train_year)]\n",
    "        X_test = Predictors[(Predictors.index.year >= end_validation_year) & (Predictors.index.year < end_test_year)]\n",
    "        X_val = Predictors[(Predictors.index.year >= end_train_year) & (Predictors.index.year < end_validation_year)]\n",
    "        y_train = Dependent[(Dependent.index.year < end_train_year)].values.ravel()\n",
    "        y_test = Dependent[(Dependent.index.year >= end_validation_year) & (Dependent.index.year < end_test_year)].values.ravel()\n",
    "        y_val = Dependent[(Dependent.index.year >= end_train_year) & (Dependent.index.year < end_validation_year)].values.ravel()\n",
    "        \n",
    "        best_par = val_fun_with_huber(ENet, params=tuning_par, X_trn=X_train, y_trn=y_train, X_vld=X_val, y_vld=y_val)\n",
    "        \n",
    "        ENetH_SP500 = ENet(lmd=best_par['lmd'], rho=best_par['rho'], L=best_par['L'],random_state=best_par['random state']).fit(X_train, y_train)\n",
    "\n",
    "        # Calculate R_squared        \n",
    "        r_stock_pred = ENetH_SP500.predict(X_test).reshape(-1)\n",
    "        \n",
    "        # Gets weights from current testing year\n",
    "        weights_test = stock_weights.loc[str(end_validation_year)]\n",
    "        # Initialize dataframe to store predicted and actual returns\n",
    "        r_portfolio = pd.DataFrame(index=weights_test.index, columns=['return_test', 'return_pred'])\n",
    "        \n",
    "        # Calculate monthly return predicted and actual \n",
    "        for month in range(1, 13):\n",
    "            start_index = (month - 1) * weights_test.shape[0] // 12  \n",
    "            end_index = month * weights_test.shape[0] // 12\n",
    "            month_weights = weights_test.iloc[start_index:end_index]\n",
    "            month_y_test = y_test[start_index:end_index]\n",
    "            month_y_pred = r_stock_pred[start_index:end_index]\n",
    "            \n",
    "            # Calculate weighted average return for the month\n",
    "            return_test = np.sum(month_weights['weight'] * month_y_test)\n",
    "            return_pred = np.sum(month_weights['weight'] * month_y_pred)\n",
    "\n",
    "            # Directly store the monthly values in the lists\n",
    "            r_port_difference_list.append((return_test - return_pred)**2)\n",
    "            r_port_actual_list.append(return_test**2)\n",
    "            iter_difference_list.append((return_test - return_pred)**2)\n",
    "            iter_actual_list.append(return_test**2)\n",
    "        \n",
    "        iter_Roo2 = R_oos(iter_difference_list,  iter_actual_list)\n",
    "        iterations_Roo2.append(iter_Roo2)\n",
    "        \n",
    "        stop = time.time()\n",
    "        print(f'Iteration number {i+1} finished, Running time {stop-start}, Roo2 iteration {i+1} = {iter_Roo2}')\n",
    "        \n",
    "    stop_gen = time.time()\n",
    "    print(f'TOTAL RUNNING TIME = {stop_gen-start_gen}.')\n",
    "    \n",
    "    # Calculate Roos\n",
    "    Model_Roos = R_oos(r_port_difference_list, r_port_actual_list)\n",
    "    Iterations_average_Roos = np.mean(iterations_Roo2)\n",
    "    \n",
    "    print('-'*46+'RESULTS'+'-'*46)\n",
    "    print(f'OverallModel Roo2: {Model_Roos} || Average of Single Iterations Roo2: {Iterations_average_Roos}')\n",
    "        \n",
    "    return Model_Roos, Iterations_average_Roos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results Elastic Net with Huber loss function\n",
    "ENet_Huber_Roos, ENet_Huber_iteravg_Roos = ENet_with_huber(Dependent=y, Predictors=X, stock_weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso + H (not adjusted to newest code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Lasso_with_huber(Dependent, Predictors, stock_weights, initial_train_years=18, validation_years=12, test_years=1):\n",
    "    \"\"\"\n",
    "Function that runs Lasso Regression with Huber Loss function.\n",
    "Input: \n",
    "    - Dependent: Dependent variable data\n",
    "    - Predictors: Independent variables data\n",
    "    - stock_weights: The weights of a stock as percentage of portfolio\n",
    "    - initial_train_years: Number of initial training years. (Default is 18)\n",
    "    - validation_years: Number of years for the validation set. (Default is 12)\n",
    "    - test_years: Number of years for the test set. (Default is 1)\n",
    "\n",
    "    Output: Out of sample R-squared.\n",
    "\"\"\"\n",
    "    # All the years(1957-2016)\n",
    "    yrs = Dependent.index.year.unique()\n",
    "    # Initalize to store r-squared for portfolio.\n",
    "    r_port_difference_list = []\n",
    "    r_port_actual_list = []\n",
    "    # Tested tuning parameters\n",
    "    tuning_par = {\n",
    "        \"alpha\": np.linspace(1e-1, 1e-4, num=10),\n",
    "        \"l1_ratio\": [1], \"tol\":[1e-2]\n",
    "    } \n",
    "    \n",
    "    for i in range(len(yrs) - initial_train_years - validation_years):\n",
    "        start_year = yrs[i]\n",
    "        end_train_year = start_year + initial_train_years\n",
    "        end_validation_year = end_train_year + validation_years\n",
    "        end_test_year = end_validation_year + test_years\n",
    "\n",
    "        X_train = Predictors[(Predictors.index.year < end_train_year)]\n",
    "        X_test = Predictors[(Predictors.index.year >= end_validation_year) & (Predictors.index.year < end_test_year)]\n",
    "        X_val = Predictors[(Predictors.index.year >= end_train_year) & (Predictors.index.year < end_validation_year)]\n",
    "        y_train = Dependent[(Dependent.index.year < end_train_year)].values.ravel()\n",
    "        y_test = Dependent[(Dependent.index.year >= end_validation_year) & (Dependent.index.year < end_test_year)].values.ravel()\n",
    "        y_val = Dependent[(Dependent.index.year >= end_train_year) & (Dependent.index.year < end_validation_year)].values.ravel()\n",
    "        \n",
    "        best_par = val_fun_with_huber(ElasticNet, params=tuning_par, X_trn=X_train, y_trn=y_train, X_vld=X_val, y_vld=y_val)\n",
    "        \n",
    "        LASH_SP500 = ElasticNet(alpha=best_par['alpha'], l1_ratio=best_par['l1_ratio']).fit(X_train, y_train)\n",
    "\n",
    "        # Calculate R_squared        \n",
    "        r_stock_pred = LASH_SP500.predict(X_test)\n",
    "        \n",
    "        # Gets weights from current testing year\n",
    "        weights_test = stock_weights.loc[str(end_validation_year)]\n",
    "        # Initialize dataframe to store predicted and actual returns\n",
    "        r_portfolio = pd.DataFrame(index=weights_test.index, columns=['return_test', 'return_pred'])\n",
    "        \n",
    "        # Calculate monthly return predicted and actual \n",
    "        for month in range(1, 13):\n",
    "            start_index = (month - 1) * weights_test.shape[0] // 12  \n",
    "            end_index = month * weights_test.shape[0] // 12\n",
    "            month_weights = weights_test.iloc[start_index:end_index]\n",
    "            month_y_test = y_test[start_index:end_index]\n",
    "            month_y_pred = r_stock_pred[start_index:end_index]\n",
    "            # Store the results in a DataFrame\n",
    "            r_portfolio.loc[f'{end_validation_year}-{month:02d}', ['return_test', 'return_pred']] = np.sum(month_weights['weight'] * month_y_test), np.sum(month_weights['weight'] * month_y_pred) \n",
    "\n",
    "        # Store numerator and denominator to calculate out of sample R-Squared\n",
    "        r_port_difference_list.extend(((r_portfolio['return_test']-r_portfolio['return_pred'])**2).tolist())\n",
    "        r_port_actual_list.extend(((r_portfolio['return_test'])**2).tolist())\n",
    "    \n",
    "    # Calculate Roos\n",
    "    Model_Roos = R_oos(r_port_difference_list, r_port_actual_list)\n",
    "\n",
    "    return Model_Roos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results Lasso Regression with Huber loss function\n",
    "Lasso_with_huber_scores = Lasso_with_huber(Dependent=y, Predictors=X, stock_weights=weights)\n",
    "Lasso_with_huber_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge + H (not adjusted to newest code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ridge_with_huber(Dependent, Predictors, stock_weights, initial_train_years=18, validation_years=12, test_years=1):\n",
    "    \"\"\"\n",
    "Function that runs Ridge Regression with Huber Loss function.\n",
    "Input: \n",
    "    - Dependent: Dependent variable data\n",
    "    - Predictors: Independent variables data\n",
    "    - stock_weights: The weights of a stock as percentage of portfolio\n",
    "    - initial_train_years: Number of initial training years. (Default is 18)\n",
    "    - validation_years: Number of years for the validation set. (Default is 12)\n",
    "    - test_years: Number of years for the test set. (Default is 1)\n",
    "\n",
    "    Output: Out of sample R-squared.\n",
    "\"\"\"\n",
    "    # All the years(1957-2016)\n",
    "    yrs = Dependent.index.year.unique()\n",
    "    # Initalize to store r-squared for portfolio.\n",
    "    r_port_difference_list = []\n",
    "    r_port_actual_list = []\n",
    "    # Tested tuning parameters\n",
    "    tuning_par = {\n",
    "        \"alpha\": np.linspace(1e-1, 1e-4, num=10),\n",
    "        \"l1_ratio\": [0], \"tol\":[1e-2]\n",
    "    } \n",
    "    \n",
    "    for i in range(len(yrs) - initial_train_years - validation_years):\n",
    "        start_year = yrs[i]\n",
    "        end_train_year = start_year + initial_train_years\n",
    "        end_validation_year = end_train_year + validation_years\n",
    "        end_test_year = end_validation_year + test_years\n",
    "\n",
    "        X_train = Predictors[(Predictors.index.year < end_train_year)]\n",
    "        X_test = Predictors[(Predictors.index.year >= end_validation_year) & (Predictors.index.year < end_test_year)]\n",
    "        X_val = Predictors[(Predictors.index.year >= end_train_year) & (Predictors.index.year < end_validation_year)]\n",
    "        y_train = Dependent[(Dependent.index.year < end_train_year)].values.ravel()\n",
    "        y_test = Dependent[(Dependent.index.year >= end_validation_year) & (Dependent.index.year < end_test_year)].values.ravel()\n",
    "        y_val = Dependent[(Dependent.index.year >= end_train_year) & (Dependent.index.year < end_validation_year)].values.ravel()\n",
    "        \n",
    "        best_par = val_fun_with_huber(ElasticNet, params=tuning_par, X_trn=X_train, y_trn=y_train, X_vld=X_val, y_vld=y_val)\n",
    "        \n",
    "        RIDH_SP500 = ElasticNet(alpha=best_par['alpha'], l1_ratio=best_par['l1_ratio']).fit(X_train, y_train)\n",
    "\n",
    "        # Calculate R_squared        \n",
    "        r_stock_pred = RIDH_SP500.predict(X_test)\n",
    "        \n",
    "        # Gets weights from current testing year\n",
    "        weights_test = stock_weights.loc[str(end_validation_year)]\n",
    "        # Initialize dataframe to store predicted and actual returns\n",
    "        r_portfolio = pd.DataFrame(index=weights_test.index, columns=['return_test', 'return_pred'])\n",
    "        \n",
    "        # Calculate monthly return predicted and actual \n",
    "        for month in range(1, 13):\n",
    "            start_index = (month - 1) * weights_test.shape[0] // 12  \n",
    "            end_index = month * weights_test.shape[0] // 12\n",
    "            month_weights = weights_test.iloc[start_index:end_index]\n",
    "            month_y_test = y_test[start_index:end_index]\n",
    "            month_y_pred = r_stock_pred[start_index:end_index]\n",
    "            # Store the results in a DataFrame\n",
    "            r_portfolio.loc[f'{end_validation_year}-{month:02d}', ['return_test', 'return_pred']] = np.sum(month_weights['weight'] * month_y_test), np.sum(month_weights['weight'] * month_y_pred) \n",
    "\n",
    "        # Store numerator and denominator to calculate out of sample R-Squared\n",
    "        r_port_difference_list.extend(((r_portfolio['return_test']-r_portfolio['return_pred'])**2).tolist())\n",
    "        r_port_actual_list.extend(((r_portfolio['return_test'])**2).tolist())\n",
    "    \n",
    "    # Calculate Roos\n",
    "    Model_Roos = R_oos(r_port_difference_list, r_port_actual_list)\n",
    "\n",
    "    return Model_Roos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results Ridge Regression with Huber loss function\n",
    "Ridge_with_huber_scores = Ridge_with_huber(Dependent=y, Predictors=X, stock_weights=weights)\n",
    "Ridge_with_huber_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - GLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GLM(y, X,stock_weights, initial_train_years=18, validation_years=12, test_years=1):\n",
    "    \"\"\"\n",
    "Function that runs Ridge Regression with Huber Loss function.\n",
    "Input: \n",
    "    - Dependent: Dependent variable data\n",
    "    - Predictors: Independent variables data\n",
    "    - stock_weights: The weights of a stock as percentage of portfolio\n",
    "    - initial_train_years: Number of initial training years. (Default is 18)\n",
    "    - validation_years: Number of years for the validation set. (Default is 12)\n",
    "    - test_years: Number of years for the test set. (Default is 1)\n",
    "\n",
    "    Output: Out of sample R-squared.\n",
    "\"\"\"\n",
    "    yrs = X.index.year.unique()\n",
    "    start_gen = time.time()\n",
    "    r_port_difference_list = []\n",
    "    r_port_actual_list = []\n",
    "    iterations_Roo2 = []\n",
    "    tuning_par = {\n",
    "    #'knots': [3],\n",
    "    'group_reg':[1e-4,1e-1],\n",
    "    'l1_reg': [1e-4,0],\n",
    "    'groups': [],\n",
    "    'random_state': [12308]\n",
    "    }\n",
    "\n",
    "    #GETTING THE SPLINES\n",
    "    spline_data = pd.DataFrame(np.ones((X.shape[0],1)),index=X.index,columns=['const'])\n",
    "    for i in X.columns:\n",
    "        i_dat = X.loc[:,i]\n",
    "        i_sqr = i_dat**2\n",
    "        i_cut, bins = pd.cut(i_dat, 3, right=True, ordered=True, retbins=True)\n",
    "        i_dum = pd.get_dummies(i_cut)\n",
    "        for j in np.arange(3):\n",
    "            i_dum.iloc[:,j] = i_dum.iloc[:,j]*((i_dat-bins[j])**2)\n",
    "        i_dum.columns = [f\"{i}_{k}\" for k in np.arange(1,3+1)]\n",
    "        spline_data = pd.concat((spline_data,i_dat,i_dum),axis=1)\n",
    "\n",
    "\n",
    "    def run_iteration(start_year):\n",
    "        start = time.time()\n",
    "        iter_difference_list = []\n",
    "        iter_actual_list = []\n",
    "        \n",
    "        start_year = yrs[i]\n",
    "        end_train_year = start_year + initial_train_years  # 18 years of training and increasing with 1 year every iteration\n",
    "        end_validation_year = end_train_year + validation_years  # 12 years of validation\n",
    "        end_test_year = end_validation_year + test_years  # 1 year of test\n",
    "\n",
    "        # Creating training, validation and test sets.\n",
    "        X_train = spline_data[(X.index.year < end_train_year)]\n",
    "        X_test = spline_data[(X.index.year >= end_validation_year) & (X.index.year < end_test_year)]\n",
    "        X_val = spline_data[(X.index.year >= end_train_year) & (X.index.year < end_validation_year)]\n",
    "        y_train = y[(y.index.year < end_train_year)].values.ravel()\n",
    "        y_test = y[(y.index.year >= end_validation_year) & (y.index.year < end_test_year)].values.ravel()\n",
    "        y_val = y[(y.index.year >= end_train_year) & (y.index.year < end_validation_year)].values.ravel()\n",
    "        \n",
    "        groups = [0]+flatten([list(np.repeat(i,3+1))[:] for i in np.arange(1,X.shape[1]+1)])\n",
    "        tuning_par['groups'] = groups\n",
    "        # This part runs the tuning to find the best combination of the tuning parameters for every split\n",
    "        best_par = val_fun(GroupLasso, params=tuning_par, X_trn=X_train, y_trn=y_train, X_vld=X_val, y_vld=y_val)\n",
    "        GL=GroupLasso(groups=best_par['groups'], group_reg=best_par['group_reg'], l1_reg=best_par['l1_reg'], fit_intercept=False, random_state=best_par['random_state'],supress_warning=True).fit(X_train,y_train)\n",
    "        #GL=GroupLasso(groups=best_par.groups,group_reg=best_par.lmd,l1_reg=best_par.l1_reg,fit_intercept=False,random_state=best_par.random_state)\n",
    "        \n",
    "        # Predict returns at the stock level\n",
    "        r_stock_pred = GL.predict(X_test)\n",
    "        \n",
    "        # Gets weights from current testing year\n",
    "        weights_test = stock_weights.loc[str(end_validation_year)]\n",
    "        # Initialize dataframe to store predicted and actual returns\n",
    "        r_portfolio = pd.DataFrame(index=weights_test.index, columns=['return_test', 'return_pred'])\n",
    "        \n",
    "        # Calculate monthly return predicted and actual \n",
    "        for month in range(1, 13):\n",
    "            start_index = (month - 1) * weights_test.shape[0] // 12  \n",
    "            end_index = month * weights_test.shape[0] // 12\n",
    "            month_weights = weights_test.iloc[start_index:end_index]\n",
    "            month_y_test = y_test[start_index:end_index]\n",
    "            month_y_pred = r_stock_pred[start_index:end_index]\n",
    "            # Calculate weighted average return for the month\n",
    "            return_test = np.sum(month_weights['weight'] * month_y_test)\n",
    "            return_pred = np.sum(month_weights['weight'] * month_y_pred)\n",
    "\n",
    "            # Directly store the monthly values in the lists\n",
    "            r_port_difference_list.append((return_test - return_pred)**2)\n",
    "            r_port_actual_list.append(return_test**2)\n",
    "            iter_difference_list.append((return_test - return_pred)**2)\n",
    "            iter_actual_list.append(return_test**2)\n",
    "        \n",
    "        iter_Roo2 = R_oos(iter_difference_list,  iter_actual_list)\n",
    "        iterations_Roo2.append(iter_Roo2)\n",
    "        \n",
    "        stop = time.time()\n",
    "        print(f'Iteration number {i+1} finished, Running time {stop-start}, Roo2 iteration {i+1} = {iter_Roo2}')\n",
    "\n",
    "        return iter_difference_list, iter_actual_list\n",
    "\n",
    "    results = Parallel(n_jobs=-1)(\n",
    "        delayed(run_iteration)(yrs[i]) for i in range(len(yrs) - initial_train_years - validation_years)\n",
    "    )\n",
    "        \n",
    "    stop_gen = time.time()\n",
    "    print(f'TOTAL RUNNING TIME = {stop_gen-start_gen}.')\n",
    "    \n",
    "    # Calculate Roos\n",
    "    Model_Roos = R_oos(r_port_difference_list, r_port_actual_list)\n",
    "    Iterations_average_Roos = np.mean(iterations_Roo2)\n",
    "    \n",
    "    print('-'*46+'RESULTS'+'-'*46)\n",
    "    print(f'OverallModel Roo2: {Model_Roos} || Average of Single Iterations Roo2: {Iterations_average_Roos}')\n",
    "        \n",
    "    return Model_Roos, Iterations_average_Roos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results GLM\n",
    "GLM_Roos, GLM_iteravg_Roos = GLM(y=y, X=X, stock_weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_F(Dependent, Predictors, stock_weights, initial_train_years=18, validation_years=12, test_years=1):\n",
    "    \"\"\"\n",
    "Function that runs Random Forest\n",
    "Input: \n",
    "    - Dependent: Dependent variable data\n",
    "    - Predictors: Independent variables data\n",
    "    - stock_weights: The weights of a stock as percentage of portfolio\n",
    "    - initial_train_years: Number of initial training years. (Default is 18)\n",
    "    - validation_years: Number of years for the validation set. (Default is 12)\n",
    "    - test_years: Number of years for the test set. (Default is 1)\n",
    "\n",
    "    Output: Out of sample R-squared.\n",
    "\"\"\"\n",
    "    yrs = Dependent.index.year.unique()\n",
    "    start_gen = time.time()\n",
    "    r_port_difference_list = []\n",
    "    r_port_actual_list = []\n",
    "    iterations_Roo2 = []\n",
    "    tuning_par = {\n",
    "    'n_estimators': [300],\n",
    "    'max_depth': [3,6],\n",
    "    'max_features': [30,50,100],\n",
    "    'random_state': [12308]\n",
    "    }\n",
    "    \n",
    "    # Now the model runs for every time of the 30 splits and for every possible combination of the tuning parameters.\n",
    "    # In this case is 30*60 = 1800, but only the best R2 for every split are stored. \n",
    "    for i in range(len(yrs) - initial_train_years - validation_years):\n",
    "        start = time.time()\n",
    "        iter_difference_list = []\n",
    "        iter_actual_list = []\n",
    "        \n",
    "        start_year = yrs[i]\n",
    "        end_train_year = start_year + initial_train_years  # 18 years of training and increasing with 1 year every iteration\n",
    "        end_validation_year = end_train_year + validation_years  # 12 years of validation\n",
    "        end_test_year = end_validation_year + test_years  # 1 year of test\n",
    "\n",
    "        # Creating training, validation and test sets.\n",
    "        X_train = Predictors[(Predictors.index.year < end_train_year)]\n",
    "        X_test = Predictors[(Predictors.index.year >= end_validation_year) & (Predictors.index.year < end_test_year)]\n",
    "        X_val = Predictors[(Predictors.index.year >= end_train_year) & (Predictors.index.year < end_validation_year)]\n",
    "        y_train = Dependent[(Dependent.index.year < end_train_year)].values.ravel()\n",
    "        y_test = Dependent[(Dependent.index.year >= end_validation_year) & (Dependent.index.year < end_test_year)].values.ravel()\n",
    "        y_val = Dependent[(Dependent.index.year >= end_train_year) & (Dependent.index.year < end_validation_year)].values.ravel()\n",
    "        \n",
    "        # This part runs the tuning to find the best combination of the tuning parameters for every split\n",
    "        best_par = val_fun(RF, params=tuning_par, X_trn=X_train, y_trn=y_train, X_vld=X_val, y_vld=y_val)\n",
    "        \n",
    "        # Now we test the model\n",
    "        RF_SP500 = RF(n_estimators=best_par['n_estimators'], max_depth=best_par['max_depth'], max_features=best_par['max_features'], \n",
    "               random_state=best_par['random_state']).fit(X_train, y_train)\n",
    "        \n",
    "        # Predict returns at the stock level\n",
    "        r_stock_pred = RF_SP500.predict(X_test)\n",
    "        \n",
    "        # Gets weights from current testing year\n",
    "        weights_test = stock_weights.loc[str(end_validation_year)]\n",
    "        # Initialize dataframe to store predicted and actual returns\n",
    "        r_portfolio = pd.DataFrame(index=weights_test.index, columns=['return_test', 'return_pred'])\n",
    "        \n",
    "        # Calculate monthly return predicted and actual \n",
    "        for month in range(1, 13):\n",
    "            start_index = (month - 1) * weights_test.shape[0] // 12  \n",
    "            end_index = month * weights_test.shape[0] // 12\n",
    "            month_weights = weights_test.iloc[start_index:end_index]\n",
    "            month_y_test = y_test[start_index:end_index]\n",
    "            month_y_pred = r_stock_pred[start_index:end_index]\n",
    "            \n",
    "            # Calculate weighted average return for the month\n",
    "            return_test = np.sum(month_weights['weight'] * month_y_test)\n",
    "            return_pred = np.sum(month_weights['weight'] * month_y_pred)\n",
    "\n",
    "            # Directly store the monthly values in the lists\n",
    "            r_port_difference_list.append((return_test - return_pred)**2)\n",
    "            r_port_actual_list.append(return_test**2)\n",
    "            iter_difference_list.append((return_test - return_pred)**2)\n",
    "            iter_actual_list.append(return_test**2)\n",
    "        \n",
    "        iter_Roo2 = R_oos(iter_difference_list,  iter_actual_list)\n",
    "        iterations_Roo2.append(iter_Roo2)\n",
    "        \n",
    "        stop = time.time()\n",
    "        print(f'Iteration number {i+1} finished, Running time {stop-start}, Roo2 iteration {i+1} = {iter_Roo2}')\n",
    "        \n",
    "    stop_gen = time.time()\n",
    "    print(f'TOTAL RUNNING TIME = {stop_gen-start_gen}.')\n",
    "    \n",
    "    # Calculate Roos\n",
    "    Model_Roos = R_oos(r_port_difference_list, r_port_actual_list)\n",
    "    Iterations_average_Roos = np.mean(iterations_Roo2)\n",
    "    \n",
    "    print('-'*46+'RESULTS'+'-'*46)\n",
    "    print(f'OverallModel Roo2: {Model_Roos} || Average of Single Iterations Roo2: {Iterations_average_Roos}')\n",
    "        \n",
    "    return Model_Roos, Iterations_average_Roos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results Random Forest\n",
    "RF_Roos, RF_iteravg_Roos = Random_F(Dependent=y, Predictors=X, stock_weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Gradient Boosted Regression Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 - Standard GBRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GBRT(Dependent, Predictors, stock_weights, initial_train_years=18, validation_years=12, test_years=1):\n",
    "    \"\"\"\n",
    "Function that runs Gradient Boosted Regression Tree\n",
    "Input: \n",
    "    - Dependent: Dependent variable data\n",
    "    - Predictors: Independent variables data\n",
    "    - stock_weights: The weights of a stock as percentage of portfolio\n",
    "    - initial_train_years: Number of initial training years. (Default is 18)\n",
    "    - validation_years: Number of years for the validation set. (Default is 12)\n",
    "    - test_years: Number of years for the test set. (Default is 1)\n",
    "\n",
    "    Output: Out of sample R-squared.\n",
    "\"\"\"\n",
    "    yrs = Predictors.index.year.unique()\n",
    "    start_gen = time.time()\n",
    "    r_port_difference_list = []\n",
    "    r_port_actual_list = []\n",
    "    iterations_Roo2 = []\n",
    "    tuning_par = {\n",
    "    'n_estimators': range(1, 150),\n",
    "    'max_depth': range(1,2),\n",
    "    'learning_rate': [0.01, 0.1]\n",
    "    }\n",
    "    \n",
    "    # Now the model runs for every time of the 30 splits and for every possible combination of the tuning parameters.\n",
    "    for i in range(len(yrs) - initial_train_years - validation_years):\n",
    "        start = time.time()\n",
    "        iter_difference_list = []\n",
    "        iter_actual_list = []\n",
    "        \n",
    "        start_year = yrs[i]\n",
    "        end_train_year = start_year + initial_train_years  # 18 years of training and increasing with 1 year every iteration\n",
    "        end_validation_year = end_train_year + validation_years  # 12 years of validation\n",
    "        end_test_year = end_validation_year + test_years  # 1 year of test\n",
    "\n",
    "        # Creating training, validation and test sets.\n",
    "        X_train = Predictors[(Predictors.index.year < end_train_year)]\n",
    "        X_test = Predictors[(Predictors.index.year >= end_validation_year) & (Predictors.index.year < end_test_year)]\n",
    "        X_val = Predictors[(Predictors.index.year >= end_train_year) & (Predictors.index.year < end_validation_year)]\n",
    "        y_train = Dependent[(Dependent.index.year < end_train_year)].values.ravel()\n",
    "        y_test = Dependent[(Dependent.index.year >= end_validation_year) & (Dependent.index.year < end_test_year)].values.ravel()\n",
    "        y_val = Dependent[(Dependent.index.year >= end_train_year) & (Dependent.index.year < end_validation_year)].values.ravel()\n",
    "\n",
    "        # This part runs the tuning to find the best combination of the tuning parameters for every split\n",
    "        best_par = val_fun(GradientBoostingRegressor, params=tuning_par, X_trn=X_train, y_trn=y_train, X_vld=X_val, y_vld=y_val)\n",
    "        \n",
    "        # Now we test the model\n",
    "        GBRT_SP500 = GradientBoostingRegressor(n_estimators=best_par['n_estimators'], max_depth=best_par['max_depth'], learning_rate=best_par['learning_rate']).fit(X_train, y_train)\n",
    "\n",
    "        r_stock_pred = GBRT_SP500.predict(X_test)\n",
    "   \n",
    "        # Gets weights from current testing year\n",
    "        weights_test = stock_weights.loc[str(end_validation_year)]\n",
    "        # Initialize dataframe to store predicted and actual returns\n",
    "        r_portfolio = pd.DataFrame(index=weights_test.index, columns=['return_test', 'return_pred'])\n",
    "        \n",
    "        # Calculate monthly return predicted and actual \n",
    "        for month in range(1, 13):\n",
    "            start_index = (month - 1) * weights_test.shape[0] // 12  \n",
    "            end_index = month * weights_test.shape[0] // 12\n",
    "            month_weights = weights_test.iloc[start_index:end_index]\n",
    "            month_y_test = y_test[start_index:end_index]\n",
    "            month_y_pred = r_stock_pred[start_index:end_index]\n",
    "            \n",
    "            # Calculate weighted average return for the month\n",
    "            return_test = np.sum(month_weights['weight'] * month_y_test)\n",
    "            return_pred = np.sum(month_weights['weight'] * month_y_pred)\n",
    "\n",
    "            # Directly store the monthly values in the lists\n",
    "            r_port_difference_list.append((return_test - return_pred)**2)\n",
    "            r_port_actual_list.append(return_test**2)\n",
    "            iter_difference_list.append((return_test - return_pred)**2)\n",
    "            iter_actual_list.append(return_test**2)\n",
    "        \n",
    "        iter_Roo2 = R_oos(iter_difference_list,  iter_actual_list)\n",
    "        iterations_Roo2.append(iter_Roo2)\n",
    "        \n",
    "        stop = time.time()\n",
    "        print(f'Iteration number {i+1} finished, Running time {stop-start}, Roo2 iteration {i+1} = {iter_Roo2}')\n",
    "        \n",
    "    stop_gen = time.time()\n",
    "    print(f'TOTAL RUNNING TIME = {stop_gen-start_gen}.')\n",
    "    \n",
    "    # Calculate Roos\n",
    "    Model_Roos = R_oos(r_port_difference_list, r_port_actual_list)\n",
    "    Iterations_average_Roos = np.mean(iterations_Roo2)\n",
    "    \n",
    "    print('-'*46+'RESULTS'+'-'*46)\n",
    "    print(f'OverallModel Roo2: {Model_Roos} || Average of Single Iterations Roo2: {Iterations_average_Roos}')\n",
    "        \n",
    "    return Model_Roos, Iterations_average_Roos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run function and get results\n",
    "GBRT_Roos, GBRT_iteravg_Roos = GBRT(Dependent=y, Predictors=X, stock_weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 - Light GBRT with Huber loss implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_huber_obj(y_true, y_pred):\n",
    "    xi = 0.999\n",
    "    y_true, y_pred = np.array(y_true).flatten(), np.array(y_pred).flatten()\n",
    "    N = len(y_true)\n",
    "    resid = y_true - y_pred\n",
    "    ind_m = np.where(np.abs(resid)<=xi)\n",
    "    ind_u = np.where(resid>xi)\n",
    "    ind_l = np.where(resid< -xi)\n",
    "    grad = np.zeros(N)\n",
    "    try:\n",
    "        grad[ind_m] = (-2*(y_true-y_pred))[ind_m]\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        grad[ind_u] = np.repeat(2*xi,N)[ind_u]\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        grad[ind_l] = np.repeat(-2*xi,N)[ind_l]\n",
    "    except:\n",
    "        pass\n",
    "    return grad/N\n",
    "\n",
    "# hessian of huber loss with respect to y_pred\n",
    "def hess_huber_obj(y_true, y_pred):\n",
    "    xi = 0.999\n",
    "    y_true, y_pred = np.array(y_true).flatten(), np.array(y_pred).flatten()\n",
    "    N = len(y_true)\n",
    "    resid = y_true - y_pred\n",
    "    ind_m = np.where(np.abs(resid)<=xi)\n",
    "    ind_u = np.where(resid>xi)\n",
    "    ind_l = np.where(resid< -xi)\n",
    "    hess = np.zeros(N)\n",
    "    try:\n",
    "        hess[ind_m] = np.repeat(2,N)[ind_m]\n",
    "    except:\n",
    "        pass\n",
    "    return hess/N\n",
    "\n",
    "# huber loss for lgbm\n",
    "def huber_obj(y_true, y_pred):\n",
    "    grad = grad_huber_obj(y_true, y_pred)\n",
    "    hess = hess_huber_obj(y_true, y_pred)\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LIGHT_GBRT(Dependent, Predictors, stock_weights, initial_train_years=18, validation_years=12, test_years=1):\n",
    "    \"\"\"\n",
    "Function that runs Gradient Boosted Regression Tree\n",
    "Input: \n",
    "    - Dependent: Dependent variable data\n",
    "    - Predictors: Independent variables data\n",
    "    - stock_weights: The weights of a stock as percentage of portfolio\n",
    "    - initial_train_years: Number of initial training years. (Default is 18)\n",
    "    - validation_years: Number of years for the validation set. (Default is 12)\n",
    "    - test_years: Number of years for the test set. (Default is 1)\n",
    "\n",
    "    Output: Out of sample R-squared.\n",
    "\"\"\"\n",
    "    yrs = Predictors.index.year.unique()\n",
    "    start_gen = time.time()\n",
    "    r_port_difference_list = []\n",
    "    r_port_actual_list = []\n",
    "    iterations_Roo2 = []\n",
    "    tuning_par =  {\n",
    "    'objective':[None, huber_obj],\n",
    "    'max_depth':[1,2],\n",
    "    'n_estimators':[10,50,100,200,500,1000],\n",
    "    'random_state':[12308],\n",
    "    'learning_rate':[.01,.1]\n",
    "}\n",
    "    \n",
    "    # Now the model runs for every time of the 30 splits and for every possible combination of the tuning parameters.\n",
    "    for i in range(len(yrs) - initial_train_years - validation_years):\n",
    "        start = time.time()\n",
    "        iter_difference_list = []\n",
    "        iter_actual_list = []\n",
    "        \n",
    "        start_year = yrs[i]\n",
    "        end_train_year = start_year + initial_train_years  # 18 years of training and increasing with 1 year every iteration\n",
    "        end_validation_year = end_train_year + validation_years  # 12 years of validation\n",
    "        end_test_year = end_validation_year + test_years  # 1 year of test\n",
    "\n",
    "        # Creating training, validation and test sets.\n",
    "        X_train = Predictors[(Predictors.index.year < end_train_year)]\n",
    "        X_test = Predictors[(Predictors.index.year >= end_validation_year) & (Predictors.index.year < end_test_year)]\n",
    "        X_val = Predictors[(Predictors.index.year >= end_train_year) & (Predictors.index.year < end_validation_year)]\n",
    "        y_train = Dependent[(Dependent.index.year < end_train_year)].values.ravel()\n",
    "        y_test = Dependent[(Dependent.index.year >= end_validation_year) & (Dependent.index.year < end_test_year)].values.ravel()\n",
    "        y_val = Dependent[(Dependent.index.year >= end_train_year) & (Dependent.index.year < end_validation_year)].values.ravel()\n",
    "\n",
    "        # This part runs the tuning to find the best combination of the tuning parameters for every split\n",
    "        best_par = val_fun(LGBMRegressor, params=tuning_par, X_trn=X_train, y_trn=y_train, X_vld=X_val, y_vld=y_val)\n",
    "        \n",
    "        # Now we test the model\n",
    "        LGBM_SP500 = LGBMRegressor(n_estimators=best_par['n_estimators'], max_depth=best_par['max_depth'], learning_rate=best_par['learning_rate']).fit(X_train, y_train)\n",
    "\n",
    "        r_stock_pred = LGBM_SP500.predict(X_test)\n",
    "   \n",
    "        # Gets weights from current testing year\n",
    "        weights_test = stock_weights.loc[str(end_validation_year)]\n",
    "        # Initialize dataframe to store predicted and actual returns\n",
    "        r_portfolio = pd.DataFrame(index=weights_test.index, columns=['return_test', 'return_pred'])\n",
    "        \n",
    "        # Calculate monthly return predicted and actual \n",
    "        for month in range(1, 13):\n",
    "            start_index = (month - 1) * weights_test.shape[0] // 12  \n",
    "            end_index = month * weights_test.shape[0] // 12\n",
    "            month_weights = weights_test.iloc[start_index:end_index]\n",
    "            month_y_test = y_test[start_index:end_index]\n",
    "            month_y_pred = r_stock_pred[start_index:end_index]\n",
    "            \n",
    "            # Calculate weighted average return for the month\n",
    "            return_test = np.sum(month_weights['weight'] * month_y_test)\n",
    "            return_pred = np.sum(month_weights['weight'] * month_y_pred)\n",
    "\n",
    "            # Directly store the monthly values in the lists\n",
    "            r_port_difference_list.append((return_test - return_pred)**2)\n",
    "            r_port_actual_list.append(return_test**2)\n",
    "            iter_difference_list.append((return_test - return_pred)**2)\n",
    "            iter_actual_list.append(return_test**2)\n",
    "        \n",
    "        iter_Roo2 = R_oos(iter_difference_list,  iter_actual_list)\n",
    "        iterations_Roo2.append(iter_Roo2)\n",
    "        \n",
    "        stop = time.time()\n",
    "        print(f'Iteration number {i+1} finished, Running time {stop-start}, Roo2 iteration {i+1} = {iter_Roo2}')\n",
    "        \n",
    "    stop_gen = time.time()\n",
    "    print(f'TOTAL RUNNING TIME = {stop_gen-start_gen}.')\n",
    "    \n",
    "    # Calculate Roos\n",
    "    Model_Roos = R_oos(r_port_difference_list, r_port_actual_list)\n",
    "    Iterations_average_Roos = np.mean(iterations_Roo2)\n",
    "    \n",
    "    print('-'*46+'RESULTS'+'-'*46)\n",
    "    print(f'OverallModel Roo2: {Model_Roos} || Average of Single Iterations Roo2: {Iterations_average_Roos}')\n",
    "        \n",
    "    return Model_Roos, Iterations_average_Roos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run function and get results\n",
    "LGBM_Roos, LGBM_iteravg_Roos = LIGHT_GBRT(Dependent=y, Predictors=X, stock_weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - Additional Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 - XGBossting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBoost(Dependent, Predictors, stock_weights, initial_train_years=18, validation_years=12, test_years=1):\n",
    "    \"\"\"\n",
    "Function that runs XGBoost\n",
    "Input: \n",
    "    - Dependent: Dependent variable data\n",
    "    - Predictors: Independent variables data\n",
    "    - stock_weights: The weights of a stock as percentage of portfolio\n",
    "    - initial_train_years: Number of initial training years. (Default is 18)\n",
    "    - validation_years: Number of years for the validation set. (Default is 12)\n",
    "    - test_years: Number of years for the test set. (Default is 1)\n",
    "\n",
    "    Output: Out of sample R-squared.\n",
    "\"\"\"\n",
    "    yrs = Dependent.index.year.unique()\n",
    "    start_gen = time.time()\n",
    "    r_port_difference_list = []\n",
    "    r_port_actual_list = []\n",
    "    iterations_Roo2 = []\n",
    "    tuning_par = {\n",
    "    'n_estimators': [500,600,800,1000],\n",
    "    'max_depth': [1,2],\n",
    "    'random_state': [12308],\n",
    "    #'learning_rate': [.01]\n",
    "    }\n",
    "    \n",
    "    # Now the model runs for every time of the 30 splits and for every possible combination of the tuning parameters.\n",
    "    # In this case is 30*60 = 1800, but only the best R2 for every split are stored. \n",
    "    for i in range(len(yrs) - initial_train_years - validation_years):\n",
    "        start = time.time()\n",
    "        iter_difference_list = []\n",
    "        iter_actual_list = []\n",
    "        \n",
    "        start_year = yrs[i]\n",
    "        end_train_year = start_year + initial_train_years  # 18 years of training and increasing with 1 year every iteration\n",
    "        end_validation_year = end_train_year + validation_years  # 12 years of validation\n",
    "        end_test_year = end_validation_year + test_years  # 1 year of test\n",
    "\n",
    "        # Creating training, validation and test sets.\n",
    "        X_train = Predictors[(Predictors.index.year < end_train_year)]\n",
    "        X_test = Predictors[(Predictors.index.year >= end_validation_year) & (Predictors.index.year < end_test_year)]\n",
    "        X_val = Predictors[(Predictors.index.year >= end_train_year) & (Predictors.index.year < end_validation_year)]\n",
    "        y_train = Dependent[(Dependent.index.year < end_train_year)].values.ravel()\n",
    "        y_test = Dependent[(Dependent.index.year >= end_validation_year) & (Dependent.index.year < end_test_year)].values.ravel()\n",
    "        y_val = Dependent[(Dependent.index.year >= end_train_year) & (Dependent.index.year < end_validation_year)].values.ravel()\n",
    "        \n",
    "        # This part runs the tuning to find the best combination of the tuning parameters for every split\n",
    "        best_par = val_fun(XGBRegressor, params=tuning_par, X_trn=X_train, y_trn=y_train, X_vld=X_val, y_vld=y_val)\n",
    "        \n",
    "        # Now we test the model\n",
    "        XGB = XGBRegressor(n_estimators=best_par['n_estimators'], max_depth=best_par['max_depth']).fit(X_train, y_train)\n",
    "        \n",
    "        # Predict returns at the stock level\n",
    "        r_stock_pred = XGB.predict(X_test)\n",
    "        \n",
    "        # Gets weights from current testing year\n",
    "        weights_test = stock_weights.loc[str(end_validation_year)]\n",
    "        # Initialize dataframe to store predicted and actual returns\n",
    "        r_portfolio = pd.DataFrame(index=weights_test.index, columns=['return_test', 'return_pred'])\n",
    "        \n",
    "        # Calculate monthly return predicted and actual \n",
    "        for month in range(1, 13):\n",
    "            start_index = (month - 1) * weights_test.shape[0] // 12  \n",
    "            end_index = month * weights_test.shape[0] // 12\n",
    "            month_weights = weights_test.iloc[start_index:end_index]\n",
    "            month_y_test = y_test[start_index:end_index]\n",
    "            month_y_pred = r_stock_pred[start_index:end_index]\n",
    "            \n",
    "            # Calculate weighted average return for the month\n",
    "            return_test = np.sum(month_weights['weight'] * month_y_test)\n",
    "            return_pred = np.sum(month_weights['weight'] * month_y_pred)\n",
    "\n",
    "            # Directly store the monthly values in the lists\n",
    "            r_port_difference_list.append((return_test - return_pred)**2)\n",
    "            r_port_actual_list.append(return_test**2)\n",
    "            iter_difference_list.append((return_test - return_pred)**2)\n",
    "            iter_actual_list.append(return_test**2)\n",
    "        \n",
    "        iter_Roo2 = R_oos(iter_difference_list,  iter_actual_list)\n",
    "        iterations_Roo2.append(iter_Roo2)\n",
    "        \n",
    "        stop = time.time()\n",
    "        print(f'Iteration number {i+1} finished, Running time {stop-start}, Roo2 iteration {i+1} = {iter_Roo2}')\n",
    "        \n",
    "    stop_gen = time.time()\n",
    "    print(f'TOTAL RUNNING TIME = {stop_gen-start_gen}.')\n",
    "    \n",
    "    # Calculate Roos\n",
    "    Model_Roos = R_oos(r_port_difference_list, r_port_actual_list)\n",
    "    Iterations_average_Roos = np.mean(iterations_Roo2)\n",
    "    \n",
    "    print('-'*46+'RESULTS'+'-'*46)\n",
    "    print(f'OverallModel Roo2: {Model_Roos} || Average of Single Iterations Roo2: {Iterations_average_Roos}')\n",
    "        \n",
    "    return Model_Roos, Iterations_average_Roos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results XGBoost\n",
    "XGB_Roos, XGB_iteravg_Roos = XGBoost(Dependent=y, Predictors=X, stock_weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 -  BART Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISLP.bart import BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BARTrees(Dependent, Predictors, stock_weights, initial_train_years=18, validation_years=12, test_years=1):\n",
    "    \"\"\"\n",
    "Function that runs Bayesian Addetive Regression Tree\n",
    "Input: \n",
    "    - Dependent: Dependent variable data\n",
    "    - Predictors: Independent variables data\n",
    "    - stock_weights: The weights of a stock as percentage of portfolio\n",
    "    - initial_train_years: Number of initial training years. (Default is 18)\n",
    "    - validation_years: Number of years for the validation set. (Default is 12)\n",
    "    - test_years: Number of years for the test set. (Default is 1)\n",
    "\n",
    "    Output: Out of sample R-squared.\n",
    "\"\"\"\n",
    "    yrs = Dependent.index.year.unique()\n",
    "    start_gen = time.time()\n",
    "    r_port_difference_list = []\n",
    "    r_port_actual_list = []\n",
    "    iterations_Roo2 = []\n",
    "    tuning_par = {\n",
    "    'num_trees': [100,200,300],\n",
    "    'burnin': [50,150,200],\n",
    "    'max_stages': [500,1000,2000]\n",
    "    }\n",
    "    \n",
    "    # Now the model runs for every time of the 30 splits and for every possible combination of the tuning parameters.\n",
    "    # In this case is 30*60 = 1800, but only the best R2 for every split are stored. \n",
    "    for i in range(len(yrs) - initial_train_years - validation_years):\n",
    "        start = time.time()\n",
    "        iter_difference_list = []\n",
    "        iter_actual_list = []\n",
    "        \n",
    "        start_year = yrs[i]\n",
    "        end_train_year = start_year + initial_train_years  # 18 years of training and increasing with 1 year every iteration\n",
    "        end_validation_year = end_train_year + validation_years  # 12 years of validation\n",
    "        end_test_year = end_validation_year + test_years  # 1 year of test\n",
    "\n",
    "        # Creating training, validation and test sets.\n",
    "        X_train = Predictors[(Predictors.index.year < end_train_year)]\n",
    "        X_test = Predictors[(Predictors.index.year >= end_validation_year) & (Predictors.index.year < end_test_year)]\n",
    "        X_val = Predictors[(Predictors.index.year >= end_train_year) & (Predictors.index.year < end_validation_year)]\n",
    "        y_train = Dependent[(Dependent.index.year < end_train_year)].values.ravel()\n",
    "        y_test = Dependent[(Dependent.index.year >= end_validation_year) & (Dependent.index.year < end_test_year)].values.ravel()\n",
    "        y_val = Dependent[(Dependent.index.year >= end_train_year) & (Dependent.index.year < end_validation_year)].values.ravel()\n",
    "        \n",
    "        # This part runs the tuning to find the best combination of the tuning parameters for every split\n",
    "        best_par = val_fun(BART, params=tuning_par, X_trn=np.asarray(X_train), y_trn=y_train, X_vld=np.asarray(X_val), y_vld=y_val)\n",
    "        \n",
    "        # Now we test the model\n",
    "        BART_SP500 = BART(num_trees=best_par['num_trees'], burnin=best_par['burnin'], max_stages=best_par['max_stages']).fit(X_train, y_train)\n",
    "        \n",
    "        # Predict returns at the stock level\n",
    "        r_stock_pred = BART_SP500.predict(np.asarray(X_test))\n",
    "        \n",
    "        # Gets weights from current testing year\n",
    "        weights_test = stock_weights.loc[str(end_validation_year)]\n",
    "        # Initialize dataframe to store predicted and actual returns\n",
    "        r_portfolio = pd.DataFrame(index=weights_test.index, columns=['return_test', 'return_pred'])\n",
    "        \n",
    "        # Calculate monthly return predicted and actual \n",
    "        for month in range(1, 13):\n",
    "            start_index = (month - 1) * weights_test.shape[0] // 12  \n",
    "            end_index = month * weights_test.shape[0] // 12\n",
    "            month_weights = weights_test.iloc[start_index:end_index]\n",
    "            month_y_test = y_test[start_index:end_index]\n",
    "            month_y_pred = r_stock_pred[start_index:end_index]\n",
    "            \n",
    "            # Calculate weighted average return for the month\n",
    "            return_test = np.sum(month_weights['weight'] * month_y_test)\n",
    "            return_pred = np.sum(month_weights['weight'] * month_y_pred)\n",
    "\n",
    "            # Directly store the monthly values in the lists\n",
    "            r_port_difference_list.append((return_test - return_pred)**2)\n",
    "            r_port_actual_list.append(return_test**2)\n",
    "            iter_difference_list.append((return_test - return_pred)**2)\n",
    "            iter_actual_list.append(return_test**2)\n",
    "        \n",
    "        iter_Roo2 = R_oos(iter_difference_list,  iter_actual_list)\n",
    "        iterations_Roo2.append(iter_Roo2)\n",
    "        \n",
    "        stop = time.time()\n",
    "        print(f'Iteration number {i+1} finished, Running time {stop-start}, Roo2 iteration {i+1} = {iter_Roo2}')\n",
    "        \n",
    "    stop_gen = time.time()\n",
    "    print(f'TOTAL RUNNING TIME = {stop_gen-start_gen}.')\n",
    "    \n",
    "    # Calculate Roos\n",
    "    Model_Roos = R_oos(r_port_difference_list, r_port_actual_list)\n",
    "    Iterations_average_Roos = np.mean(iterations_Roo2)\n",
    "    \n",
    "    print('-'*46+'RESULTS'+'-'*46)\n",
    "    print(f'OverallModel Roo2: {Model_Roos} || Average of Single Iterations Roo2: {Iterations_average_Roos}')\n",
    "        \n",
    "    return Model_Roos, Iterations_average_Roos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results BART\n",
    "BART_Roos, BART_iteravg_Roos = BARTrees(Dependent=y, Predictors=X, stock_weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bagging(Dependent, Predictors, stock_weights, initial_train_years=18, validation_years=12, test_years=1):\n",
    "    \"\"\"\n",
    "Function that adds Bagging to the Random Forest\n",
    "Input: \n",
    "    - Dependent: Dependent variable data\n",
    "    - Predictors: Independent variables data\n",
    "    - stock_weights: The weights of a stock as percentage of portfolio\n",
    "    - initial_train_years: Number of initial training years. (Default is 18)\n",
    "    - validation_years: Number of years for the validation set. (Default is 12)\n",
    "    - test_years: Number of years for the test set. (Default is 1)\n",
    "\n",
    "    Output: Out of sample R-squared.\n",
    "\"\"\"\n",
    "    yrs = Dependent.index.year.unique()\n",
    "    start_gen = time.time()\n",
    "    r_port_difference_list = []\n",
    "    r_port_actual_list = []\n",
    "    iterations_Roo2 = []\n",
    "    tuning_par = {\n",
    "    'n_estimators': [300],\n",
    "    'max_depth': [3,6],\n",
    "    'random_state': [12308]\n",
    "    }\n",
    "    \n",
    "    # Now the model runs for every time of the 30 splits and for every possible combination of the tuning parameters.\n",
    "    # In this case is 30*60 = 1800, but only the best R2 for every split are stored. \n",
    "    for i in range(len(yrs) - initial_train_years - validation_years):\n",
    "        start = time.time()\n",
    "        iter_difference_list = []\n",
    "        iter_actual_list = []\n",
    "        \n",
    "        start_year = yrs[i]\n",
    "        end_train_year = start_year + initial_train_years  # 18 years of training and increasing with 1 year every iteration\n",
    "        end_validation_year = end_train_year + validation_years  # 12 years of validation\n",
    "        end_test_year = end_validation_year + test_years  # 1 year of test\n",
    "\n",
    "        # Creating training, validation and test sets.\n",
    "        X_train = Predictors[(Predictors.index.year < end_train_year)]\n",
    "        X_test = Predictors[(Predictors.index.year >= end_validation_year) & (Predictors.index.year < end_test_year)]\n",
    "        X_val = Predictors[(Predictors.index.year >= end_train_year) & (Predictors.index.year < end_validation_year)]\n",
    "        y_train = Dependent[(Dependent.index.year < end_train_year)].values.ravel()\n",
    "        y_test = Dependent[(Dependent.index.year >= end_validation_year) & (Dependent.index.year < end_test_year)].values.ravel()\n",
    "        y_val = Dependent[(Dependent.index.year >= end_train_year) & (Dependent.index.year < end_validation_year)].values.ravel()\n",
    "        \n",
    "        # This part runs the tuning to find the best combination of the tuning parameters for every split\n",
    "        best_par = val_fun(RF, params=tuning_par, X_trn=X_train, y_trn=y_train, X_vld=X_val, y_vld=y_val)\n",
    "        \n",
    "        # Now we test the model\n",
    "        BAG_SP500 = RF(n_estimators=best_par['n_estimators'], max_depth=best_par['max_depth'], max_features=X_train.shape[1], \n",
    "               random_state=best_par['random_state']).fit(X_train, y_train)\n",
    "        \n",
    "        # Predict returns at the stock level\n",
    "        r_stock_pred = BAG_SP500.predict(X_test)\n",
    "        \n",
    "        # Gets weights from current testing year\n",
    "        weights_test = stock_weights.loc[str(end_validation_year)]\n",
    "        # Initialize dataframe to store predicted and actual returns\n",
    "        r_portfolio = pd.DataFrame(index=weights_test.index, columns=['return_test', 'return_pred'])\n",
    "        \n",
    "        # Calculate monthly return predicted and actual \n",
    "        for month in range(1, 13):\n",
    "            start_index = (month - 1) * weights_test.shape[0] // 12  \n",
    "            end_index = month * weights_test.shape[0] // 12\n",
    "            month_weights = weights_test.iloc[start_index:end_index]\n",
    "            month_y_test = y_test[start_index:end_index]\n",
    "            month_y_pred = r_stock_pred[start_index:end_index]\n",
    "            # Calculate weighted average return for the month\n",
    "            return_test = np.sum(month_weights['weight'] * month_y_test)\n",
    "            return_pred = np.sum(month_weights['weight'] * month_y_pred)\n",
    "\n",
    "            # Directly store the monthly values in the lists\n",
    "            r_port_difference_list.append((return_test - return_pred)**2)\n",
    "            r_port_actual_list.append(return_test**2)\n",
    "            iter_difference_list.append((return_test - return_pred)**2)\n",
    "            iter_actual_list.append(return_test**2)\n",
    "        \n",
    "        iter_Roo2 = R_oos(iter_difference_list,  iter_actual_list)\n",
    "        iterations_Roo2.append(iter_Roo2)\n",
    "        \n",
    "        stop = time.time()\n",
    "        print(f'Iteration number {i+1} finished, Running time {stop-start}, Roo2 iteration {i+1} = {iter_Roo2}')\n",
    "        \n",
    "    stop_gen = time.time()\n",
    "    print(f'TOTAL RUNNING TIME = {stop_gen-start_gen}.')\n",
    "    \n",
    "    # Calculate Roos\n",
    "    Model_Roos = R_oos(r_port_difference_list, r_port_actual_list)\n",
    "    Iterations_average_Roos = np.mean(iterations_Roo2)\n",
    "    \n",
    "    print('-'*46+'RESULTS'+'-'*46)\n",
    "    print(f'OverallModel Roo2: {Model_Roos} || Average of Single Iterations Roo2: {Iterations_average_Roos}')\n",
    "        \n",
    "    return Model_Roos, Iterations_average_Roos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results Bagging\n",
    "Bagging_Roos, Bagging_iteravg_Roos = Bagging(Dependent=y, Predictors=X, stock_weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 -  Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_function(Dependent, Predictors, stock_weights, num_layers, ensemble = 10, initial_train_years=18, validation_years=12, test_years=1):\n",
    "    \"\"\"\n",
    "Function that creates Neural Network\n",
    "Input: \n",
    "    - Dependent: Dependent variable data\n",
    "    - Predictors: Independent variables data\n",
    "    - stock_weights: The weights of a stock as percentage of portfolio\n",
    "    - num_layers: The number of layers in the Neural Network\n",
    "    - ensemble: Amount of Neural Networks to be trained on same data.\n",
    "    - initial_train_years: Number of initial training years. (Default is 18)\n",
    "    - validation_years: Number of years for the validation set. (Default is 12)\n",
    "    - test_years: Number of years for the test set. (Default is 1)\n",
    "\n",
    "    Output: Out of sample R-squared.\n",
    "\"\"\"\n",
    "    yrs = Dependent.index.year.unique()\n",
    "    start_gen = time.time()\n",
    "    r_port_difference_list = []\n",
    "    r_port_actual_list = []\n",
    "    iterations_Roo2 = []\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    for i in range(len(yrs) - initial_train_years - validation_years):\n",
    "        start = time.time()\n",
    "        iter_difference_list = []\n",
    "        iter_actual_list = []\n",
    "        \n",
    "        start_year = yrs[i]\n",
    "        end_train_year = start_year + initial_train_years  # 18 years of training and increasing with 1 year every iteration\n",
    "        end_validation_year = end_train_year + validation_years  # 12 years of validation\n",
    "        end_test_year = end_validation_year + test_years  # 1 year of test\n",
    "\n",
    "        # Creating training, validation and test sets.\n",
    "        X_train = Predictors[(Predictors.index.year < end_train_year)]\n",
    "        X_test = Predictors[(Predictors.index.year >= end_validation_year) & (Predictors.index.year < end_test_year)]\n",
    "        X_val = Predictors[(Predictors.index.year >= end_train_year) & (Predictors.index.year < end_validation_year)]\n",
    "        y_train = Dependent[(Dependent.index.year < end_train_year)].values.ravel()\n",
    "        y_test = Dependent[(Dependent.index.year >= end_validation_year) & (Dependent.index.year < end_test_year)].values.ravel()\n",
    "        y_val = Dependent[(Dependent.index.year >= end_train_year) & (Dependent.index.year < end_validation_year)].values.ravel()\n",
    "         \n",
    "        tuning_par = {\n",
    "        'n_layers': [num_layers],\n",
    "        'loss': ['mse'],\n",
    "        'l1': [1e-5, 1e-3],\n",
    "        'learning_rate': [.001, .01],\n",
    "        'batch_size': [10000],\n",
    "        'epochs': [100],\n",
    "        'batch_norm': [True],\n",
    "        'random_state': [1],\n",
    "        'patience': [5],\n",
    "        'verbose': [0],\n",
    "        'monitor': ['val_loss']}\n",
    "        # NN class\n",
    "        class NN(nn.Module):\n",
    "            def __init__(\n",
    "                self, n_layers=1, loss='mse', l1=1e-5, l2=0, learning_rate=.01, batch_norm=True, patience=5,\n",
    "                epochs=100, batch_size=10000, verbose=1, random_state=1, monitor='val_loss', base_neurons=5\n",
    "            ):\n",
    "                super(NN, self).__init__()\n",
    "                self.n_layers = n_layers\n",
    "                self.l1 = l1\n",
    "                self.l2 = l2\n",
    "                self.learning_rate = learning_rate\n",
    "                self.batch_norm = batch_norm\n",
    "                self.patience = patience\n",
    "                self.epochs = epochs\n",
    "                self.batch_size = batch_size\n",
    "                self.verbose = verbose\n",
    "                self.monitor = monitor\n",
    "                self.base_neurons = base_neurons\n",
    "                self.random_state = random_state\n",
    "\n",
    "                # Initialize model layers\n",
    "                self.layers = nn.ModuleList()\n",
    "                input_size, output_size = None, 1\n",
    "\n",
    "                for i in range(self.n_layers, 0, -1):\n",
    "                    in_features = input_size if input_size is not None else X_train.shape[1]\n",
    "                    out_features = 2 ** (self.base_neurons - (self.n_layers - i))\n",
    "                    self.layers.append(nn.Linear(in_features, out_features))\n",
    "                    self.layers.append(nn.ReLU())\n",
    "                    input_size = out_features\n",
    "                    if self.batch_norm:\n",
    "                        self.layers.append(nn.BatchNorm1d(out_features))\n",
    "\n",
    "                self.layers.append(nn.Linear(input_size, output_size))\n",
    "\n",
    "                # Loss function\n",
    "                self.criterion = nn.L1Loss()\n",
    "\n",
    "                # Optimizer\n",
    "                self.optimizer = Adam(self.parameters(), lr=self.learning_rate, weight_decay=self.l1 + self.l2)\n",
    "\n",
    "            def forward(self, x):\n",
    "                for layer in self.layers:\n",
    "                    x = layer(x)\n",
    "                return x\n",
    "\n",
    "            def fit(self, X_train, y_train, X_val, y_val):\n",
    "                torch.manual_seed(self.random_state)\n",
    "                np.random.seed(self.random_state)\n",
    "                random.seed(self.random_state)\n",
    "\n",
    "                X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
    "                y_train_tensor = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1).to(device)\n",
    "                X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32).to(device)\n",
    "                y_val_tensor = torch.tensor(y_val, dtype=torch.float32).reshape(-1, 1).to(device)\n",
    "\n",
    "\n",
    "                train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "                train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=False, pin_memory=True, num_workers=4) # Change this depending on number of CPU's\n",
    "\n",
    "                early_stop_counter = 0\n",
    "                best_loss = float('inf')\n",
    "\n",
    "                for epoch in range(self.epochs):\n",
    "                    self.train()\n",
    "                    for inputs, targets in train_loader:\n",
    "                        self.optimizer.zero_grad()\n",
    "                        outputs = self(inputs)\n",
    "                        loss = self.criterion(outputs, targets)\n",
    "                        loss.backward()\n",
    "                        self.optimizer.step()\n",
    "\n",
    "                    # Validation loss\n",
    "                    self.eval()\n",
    "                    with torch.no_grad():\n",
    "                        outputs = self(X_val_tensor)\n",
    "                        val_loss = self.criterion(outputs, y_val_tensor)\n",
    "\n",
    "                    if val_loss < best_loss:\n",
    "                        best_loss = val_loss\n",
    "                        early_stop_counter = 0\n",
    "                    else:\n",
    "                        early_stop_counter += 1\n",
    "\n",
    "                    if early_stop_counter >= self.patience:\n",
    "                        print(\"Early stopping.\")\n",
    "                        break\n",
    "\n",
    "                    if self.verbose and epoch % self.verbose == 0:\n",
    "                        print(f\"Epoch {epoch + 1}/{self.epochs}, Validation Loss: {val_loss:.6f}\")\n",
    "\n",
    "                return self\n",
    "\n",
    "            def predict(self, X):\n",
    "                self.eval()\n",
    "                with torch.no_grad():\n",
    "                    X_tensor = torch.tensor(X.values, dtype=torch.float32).to(device)\n",
    "                    return self(X_tensor).cpu().numpy()\n",
    "\n",
    "\n",
    "        # Ensemble\n",
    "        ensemble_predictions = []\n",
    "        for _ in range(ensemble):\n",
    "            # Create and fit a new neural network instance\n",
    "            best_NN = val_fun_NN(NN, params=tuning_par, X_trn=X_train, y_trn=y_train, X_vld=X_val, y_vld=y_val)\n",
    "            # Store prediction for this model\n",
    "            ensemble_predictions.append(best_NN.predict(X_test).reshape(-1))  \n",
    "\n",
    "        # Average predictions from all models in the ensemble\n",
    "        r_stock_pred = np.mean(ensemble_predictions, axis=0)\n",
    "\n",
    "        weights_test = stock_weights.loc[str(end_validation_year)]\n",
    "        # Portofolio test\n",
    "        dates = weights_test.index\n",
    "        \n",
    "        # Calculate portfolio return actual \n",
    "        for month in range(1, 13):\n",
    "            start_index = (month - 1) * weights_test.shape[0] // 12  \n",
    "            end_index = month * weights_test.shape[0] // 12\n",
    "            month_weights = weights_test.iloc[start_index:end_index]\n",
    "            month_y_test = y_test[start_index:end_index]\n",
    "            month_y_pred = r_stock_pred[start_index:end_index]\n",
    "            \n",
    "            # Calculate weighted average return for the month\n",
    "            return_test = np.sum(month_weights['weight'] * month_y_test)\n",
    "            return_pred = np.sum(month_weights['weight'] * month_y_pred)\n",
    "\n",
    "            # Directly store the monthly values in the lists\n",
    "            r_port_difference_list.append((return_test - return_pred)**2)\n",
    "            r_port_actual_list.append(return_test**2)\n",
    "            iter_difference_list.append((return_test - return_pred)**2)\n",
    "            iter_actual_list.append(return_test**2)\n",
    "        \n",
    "        iter_Roo2 = R_oos(iter_difference_list,  iter_actual_list)\n",
    "        iterations_Roo2.append(iter_Roo2)\n",
    "        \n",
    "        stop = time.time()\n",
    "        print(f'Iteration number {i+1} finished, Running time {stop-start}, Roo2 iteration {i+1} = {iter_Roo2}')\n",
    "        \n",
    "    stop_gen = time.time()\n",
    "    print(f'TOTAL RUNNING TIME = {stop_gen-start_gen}.')\n",
    "    \n",
    "    # Calculate Roos\n",
    "    Model_Roos = R_oos(r_port_difference_list, r_port_actual_list)\n",
    "    Iterations_average_Roos = np.mean(iterations_Roo2)\n",
    "    \n",
    "    print('-'*46+'RESULTS'+'-'*46)\n",
    "    print(f'OverallModel Roo2: {Model_Roos} || Average of Single Iterations Roo2: {Iterations_average_Roos}')\n",
    "        \n",
    "    return Model_Roos, Iterations_average_Roos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to CUDA if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results NN1-Regression-[32(relu)-1(linear)]\n",
    "NN_1_Roos, NN_1_iteravg_Roos = NN_function(Dependent=y, Predictors=X, stock_weights=weights, num_layers=1, initial_train_years=18, validation_years=12, test_years=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results NN2-Regression-[32(relu)-16(relu)-1(linear)]\n",
    "NN_2_Roos, NN_2_iteravg_Roos = NN_function(Dependent=y, Predictors=X, stock_weights=weights, num_layers=2, initial_train_years=18, validation_years=12, test_years=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results NN3-Regression-[32(relu)-16(relu)-8(relu)-1(linear)]\n",
    "NN_3_Roos, NN_3_iteravg_Roos = NN_function(Dependent=y, Predictors=X, stock_weights=weights, num_layers=3, initial_train_years=18, validation_years=12, test_years=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results NN4-Regression-[32(relu)-16(relu)-8(relu)-4(relu)-1(linear)]\n",
    "NN_4_Roos, NN_4_iteravg_Roos = NN_function(Dependent=y, Predictors=X, stock_weights=weights, num_layers=4, initial_train_years=18, validation_years=12, test_years=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NN5-Regression-[32(relu)-16(relu)-8(relu)-4(relu)-2(relu)-1(linear)]\n",
    "NN_5_Roos, NN_5_iteravg_Roos = NN_function(Dependent=y, Predictors=X, stock_weights=weights, num_layers=5, initial_train_years=18, validation_years=12, test_years=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
