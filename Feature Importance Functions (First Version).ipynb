{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panel Predictive R-squared\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def reduction_in_r2_importance(model, X, y):\n",
    "    \"\"\"Calculates feature importance using reduction in panel predictive R².\n",
    "\n",
    "    Args:\n",
    "        model (fitted model): The trained machine learning model.\n",
    "        X (pd.DataFrame or np.array): The matrix of features.\n",
    "        y (pd.Series or np.array): The target variable.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Feature importances as reductions in R².\n",
    "    \"\"\"\n",
    "    \n",
    "    original_r2 = R_oos(model.predict(X), y)\n",
    "\n",
    "    importances = []\n",
    "    for col in X.columns:\n",
    "        X_copy = X.copy()\n",
    "        X_copy[col] = 0  # Set all values of the feature to zero\n",
    "        reduced_r2 = R_oos(model.predict(X_copy), y)\n",
    "        importance = original_r2 - reduced_r2\n",
    "        importances.append(importance)\n",
    "\n",
    "    return pd.Series(importances, index=X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of Squared Partial Derivatives (SSD) for Neural Networks\n",
    "\n",
    "import torch\n",
    "\n",
    "def ssd_importance(model, X):\n",
    "    \"\"\"Calculates feature importance using sum of squared partial derivatives (SSD).\n",
    "\n",
    "    Args:\n",
    "        model (PyTorch model): The trained neural network model.\n",
    "        X (torch.Tensor): The matrix of features as a PyTorch tensor.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Feature importances as SSD values.\n",
    "    \"\"\"\n",
    "\n",
    "    X.requires_grad = True  # Enables calculation of gradients\n",
    "\n",
    "    predictions = model(X)\n",
    "    importances = []\n",
    "    for i in range(predictions.shape[1]):  # Assume output is per-feature\n",
    "        gradients = torch.autograd.grad(predictions[:, i], X, create_graph=True)[0]\n",
    "        importance = torch.sum(gradients ** 2, dim=0)  # Sum of squared gradients over samples\n",
    "        importances.append(importance.detach().numpy())  # Convert to NumPy\n",
    "\n",
    "    return torch.tensor(importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Decrease in Impurity (MDI) for Random Forests and Boosted Trees\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, y)\n",
    "importances = rf.feature_importances_\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
